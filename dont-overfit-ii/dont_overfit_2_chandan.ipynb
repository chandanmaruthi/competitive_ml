{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, log_loss, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict, RepeatedStratifiedKFold\n",
    "from warnings import filterwarnings\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import svm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (250, 302)\n",
      "test data shape (19750, 301)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "do_sample = False\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "print(\"train data shape\", train.shape)\n",
    "print(\"test data shape\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...  \\\n",
       "0   0     1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276  ...   \n",
       "1   1     0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  ...   \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "\n",
       "[2 rows x 302 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train.drop(['id','target'],axis = 1)\n",
    "test_input  = test.drop(['id'],axis = 1)\n",
    "train_cols = train_input.columns\n",
    "test_cols = test_input.columns\n",
    "\n",
    "train_labels = train['target']\n",
    "\n",
    "#app_train = pd.get_dummies(train_input)\n",
    "#app_test = pd.get_dummies(test_input)\n",
    "\n",
    "#imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#imp_mean.fit(app_train)\n",
    "#train_imputed = imp_mean.transform(app_train)\n",
    "#test_imputed = imp_mean.transform(app_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_imputed = scaler.transform(train_input)\n",
    "test_imputed = scaler.transform(test_input)\n",
    "train_df = pd.DataFrame(train_imputed, columns = train_cols)\n",
    "test_df = pd.DataFrame(test_imputed, columns = test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = list(train_df.columns)\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n",
    "random_forest.fit(train_df,train_labels)\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': features, 'importance':feature_importance_values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAGDCAYAAABnZBdiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucXXV97//XW8iIAl4QMRJigha0qEmoUbGI9VIvxSjeUDkWr220WoUetHjpqbb99VdpldZLz/GkAtJKUSvgBS+Voyj1UnSCyUAIeBRICI1GShVEhRnyOX/slXY7TjKT2Xtmzex5PR+P/cja3/Vda33WN5s8Pny/3/VdqSokSZLUjru1HYAkSdJCZjImSZLUIpMxSZKkFpmMSZIktchkTJIkqUUmY5IkSS0yGZMkSWqRyZi0ACW5IcnPkvyk63Noj+d8YpJt/Ypxitf8UJL/bzavuTtJ3pHkw23HIWn+MRmTFq5nVdUBXZ9/azOYJPu2ef1ezOfYJbXPZEzSL0hyTJKvJ/lRko1Jnti17xVJNie5Lcl1SV7dlO8PfA44tLunbXzP1fjes6aH7vQkI8DtSfZtjrsgyQ+TXJ/kDVOMe3mSamK8Mcl/JHlNkkcnGWnu5/1d9V+e5GtJ3p/kx0muSfKUrv2HJvlUkluSfDfJ73bte0eSjyf5cJJbgdcAbwVe1Nz7xj21V3dbJDktyY4k25O8omv/PZK8O8mWJr6vJrnHZH9HkuYf/29O0n9KsgT4DHAy8HngKcAFSR5WVT8EdgBrgOuAJwCfS/KtqroiyW8BH66qw7rON5XLngQ8E7gZ2Al8GvhkU34Y8H+SXFtV/zzF23gscEQT36ea+/hNYBHw7ST/VFVf6ar7ceBg4HnAhUkOr6pbgI8AVwGHAg8DLknyvar6UnPsCcCJwEuBuzfn+JWq+u2uWHbbXs3+xcC9gSXAU4GPJ/lEVf0H8C7g4cCvA99vYt05hb8jSfOMPWPSwvWJpmflR0k+0ZT9NvDZqvpsVe2sqkuAYeB4gKr6TFV9rzq+AnwBOK7HON5bVTdW1c+ARwP3r6o/rao7q+o64O+AF+/F+f6sqn5eVV8AbgfOr6odVXUT8C/A0V11dwB/U1WjVfVR4FrgmUmWAscCpzfn2gB8kE7itcs3quoTTTv9bKJAptBeo8CfNtf/LPAT4KFJ7ga8Ejilqm6qqruq6utVdQeT/B1Jmn/sGZMWrudU1f8ZV7YMODHJs7rKFgGXAjS9X28HjqTzP3P3BK7sMY4bx13/0CQ/6irbh04SNVU/6Nr+2QTfD+j6flNVVdf3LXR6wg4Fbqmq28btW72buCc0hfb696oa6/r+0ya+g4H9gO9NcNo9/h1Jmn9MxiR1uxH4h6r63fE7ktwduIBO79Anq2q06VHbNRZZ44+h0zN1z67viyeo033cjcD1VXXEdIKfhiVJ0pWQPYjO0Oa/AQclObArIXsQcFPXsePv9xe+T6G99uRm4OfAQ4CN4/bt9u9I0vzkMKWkbh8GnpXk6Un2SbJfM9H8MGCIztyoHwJjTa/P07qO/QFwvyT37irbAByf5KAki4FTJ7n+N4Hbmkn992hieESSR/ftDn/RIcAbkixKciLwq3SGAG8Evg78RdMGK4BX0Wmf3fkBsLwZYoTJ22u3qmoncDZwZvMgwT5JHtckeHv6O5I0D5mMSfpPTRJyAp0nA39IpxfmTcDdmh6iNwAfA/4D+G90epF2HXsNcD5wXTMP7VDgH+j07NxAZ77URye5/l10JryvAq6n00P0QTqT3GfC5XQm+98M/Dnwgqr692bfScByOr1kFwFvn2BYt9s/NX/+e5IrJmuvKXgjnSHNbwG3AGfQ+XvY7d/RXpxb0hySX5wuIUkLQ5KXA79TVY9vOxZJC5v/JyVJktQikzFJkqQWOUwpSZLUInvGJEmSWmQyJkmS1KI5sejrwQcfXMuXL287DEmSpEmtX7/+5qq6f7/ONyeSseXLlzM8PNx2GJIkSZNKsqWf53OYUpIkqUUmY5IkSS0yGZMkSWqRyZgkSVKLTMYkSZJaZDImSZLUIpMxSZKkFpmMSZIktchkTJIkqUUmY5IkSS0yGZMkSWqRyZgkSVKL5sSLwjeOjJCk7TAkSdI8tnjJUrZv29p2GHttTiRjY6OjLDv94rbDkCRJ89iWM9a0HcK0OEwpSZLUIpMxSZKkFpmMSZIktainZCzJfkm+mWRjkk1J/qQpP6spG0ny8SQH9CdcSZKkwdJrz9gdwJOraiWwCnhGkmOAP6iqlVW1AtgK/H6P15EkSRpIPT1NWVUF/KT5uqj5VFXdCpDOehX3AKqX60iSJA2qnueMJdknyQZgB3BJVV3elJ8DfB94GPC+CY5bm2Q4yXCvMUiSJM1XPSdjVXVXVa0CDgMek+QRTfkrgEOBzcCLJjhuXVWtrqrVvcYgSZI0X/Xtacqq+hFwKfCMrrK7gI8Az+/XdSRJkgZJr09T3j/JfZrtewBPBa5N8itNWYBnA9f0GqgkSdIg6vV1SA8Ezk2yD53E7mPAZ4B/SXIvIMBG4Pd6vI4kSdJA6vVpyhHg6Al2HdvLeSVJkhYKV+CXJElqkcmYJElSi9JZt7Vdi4aGamx0tO0wJEnSPLZ4yVK2b9s649dJsr6fS3P1OoG/L1auWMHwsGu/SpKkhcdhSkmSpBaZjEmSJLVoTgxTbhwZobM+rCRpMrM1L0bS7JgTydjY6CjLTr+47TAkaV7YcsaatkOQ1EcOU0qSJLXIZEySJKlFJmOSJEkt6ikZS3KfJB9Pck2SzUkel+QdSW5KsqH5HN+vYCVJkgZNrxP43wN8vqpekGQIuCfwdOCvq+pdPUcnSZI04KadjCW5N/AE4OUAVXUncKdLVEiSJE1dL8OUhwM/BM5J8u0kH0yyf7Pv95OMJDk7yX17D1OSJGkw9ZKM7Qv8GvC/qupo4HbgzcD/Ah4CrAK2A++e6OAka5MMJ/GllJIkacHqJRnbBmyrqsub7x8Hfq2qflBVd1XVTuDvgMdMdHBVrauq1f1867kkSdJ8M+1krKq+D9yY5KFN0VOAq5M8sKvac4GreohPkiRpoPX6NOXrgfOaJymvA14BvDfJKqCAG4BX93gNSZKkgdVTMlZVG4Dxw4wn93JOSZKkhcQV+CVJklpkMiZJktQikzFJkqQWparajoFFQ0M1NjradhiSNC8sXrKU7du2th2GtGAlWd/Ppbl6fZqyL1auWMHwsGu/SpKkhcdhSkmSpBaZjEmSJLVoTgxTbhwZIUnbYUjzmvOIJGl+mhPJ2NjoKMtOv7jtMKR5bcsZa9oOQZI0DQ5TSpIktchkTJIkqUXTTsaSLE1yaZKrk2xKcsq4/aclqSQH9x6mJEnSYOplztgYcFpVXZHkQGB9kkuq6uokS4GnAc4mliRJ2oNp94xV1faquqLZvg3YDCxpdv818IdA+8v7S5IkzWF9mTOWZDlwNHB5khOAm6pqYz/OLUmSNMh6XtoiyQHABcCpdIYu30pniHKy49YCa3u9viRJ0nzWU89YkkV0ErHzqupC4CHA4cDGJDcAhwFXJFk8/tiqWldVq/v5ok1JkqT5Zto9Y+ksmX8WsLmqzgSoqiuBQ7rq3ACsrqqbe4xTkiRpIPXSM3YscDLw5CQbms/xfYpLkiRpQZh2z1hVfRXY4wslq2r5dM8vSZK0ELgCvyRJUotMxiRJklpkMiZJktSiVLW/SP6ioaEaGx1tOwxpXlu8ZCnbt/kGMkmaaUnW93Nprp4Xfe2HlStWMDw83HYYkiRJs85hSkmSpBaZjEmSJLVoTgxTbhwZobOgvzSYnM8lSdqdOZGMjY2Osuz0i9sOQ5oxW85Y03YIkqQ5ymFKSZKkFpmMSZIktWjSZCzJ0iSXJrk6yaYkpzTlJzbfdyZZ3VX/JV0vDt/Q7F81kzchSZI0X01lztgYcFpVXZHkQGB9kkuAq4DnAf+7u3JVnQecB5DkkcAnqmpDf8OWJEkaDJMmY1W1HdjebN+WZDOwpKouASZ7CvIk4CN9iFOSJGkg7dXTlEmWA0cDl0/xkBcBJ+xdSJIkSQvHlJOxJAcAFwCnVtWtU6j/WOCnVXXVbvavBdZO9fqSJEmDaErJWJJFdBKx86rqwime+8XA+bvbWVXrgHXN+dt/W7kkSVILJk3G0pkUdhawuarOnMpJk9wNeCFwXG/hSZIkDbap9IwdC5wMXJlk11ORbwXuDrwPuD/wmSQbqurpzf4nADdW1XX9DliSJGmQTOVpyq8Cu3tk8qLdHPNl4JjphyVJkrQwuAK/JElSi0zGJEmSWmQyJkmS1KJUtb+qxKKhoRobHW07DGnGLF6ylO3btrYdhiSpD5Ksr6rVk9ecmr1agX+mrFyxguHh4bbDkCRJmnUOU0qSJLXIZEySJKlFc2KYcuPICJ2F/qXB4lwxSdJk5kQyNjY6yrLTL247DKnvtpyxpu0QJElznMOUkiRJLTIZkyRJatGkyViSs5PsSHJVV9mJSTYl2ZlkdVf5S5Js6PrsTLJqpoKXJEma76bSM/Yh4Bnjyq4Cngdc1l1YVedV1aqqWgWcDFxfVRv6EagkSdIgmnQCf1VdlmT5uLLNwGRPQJ4EfKSH2CRJkgbeTD5N+SLghBk8vyRJ0rw3I8lYkscCP62qq/ZQZy2wdiauL0mSNF/MVM/Yi4Hz91ShqtYB6wCStP+2ckmSpBb0PRlLcjfghcBx/T63JEnSoJnK0hbnA98AHppkW5JXJXlukm3A44DPJPnnrkOeANxYVdfNTMiSJEmDYypPU560m10X7ab+l4FjeohJkiRpwXAFfkmSpBaZjEmSJLXIZEySJKlFqWp/VYlFQ0M1NjradhhS3y1espTt27a2HYYkqY+SrK+q1ZPXnJqZXIF/ylauWMHw8HDbYUiSJM06hyklSZJaZDImSZLUojkxTLlxZIQkbYehBc75XZKkNsyJZGxsdJRlp1/cdhha4LacsabtECRJC5DDlJIkSS0yGZMkSWrRVF4UvjTJpUmuTrIpySlN+UFJLknyf5s/79uUPyzJN5LckeSNM30DkiRJ89lUesbGgNOq6ig6LwB/XZKjgDcDX6yqI4AvNt8BbgHeALxrBuKVJEkaKJMmY1W1vaquaLZvAzYDS4ATgHObaucCz2nq7KiqbwEuqS9JkjSJvZozlmQ5cDRwOfCAqtre7Po+8IC+RiZJkrQATHlpiyQHABcAp1bVrd3rglVVJdmrl1wmWQus3ZtjJEmSBs2UesaSLKKTiJ1XVRc2xT9I8sBm/wOBHXtz4apaV1Wr+/miTUmSpPlmKk9TBjgL2FxVZ3bt+hTwsmb7ZcAn+x+eJEnSYJvKMOWxwMnAlUk2NGVvBd4JfCzJq4AtwAsBkiwGhoF7ATuTnAocVVW39jt4SZKk+W7SZKyqvgrs7sWRT5mg/veBw3qMS5IkaUFwBX5JkqQWmYxJkiS1yGRMkiSpRanaq+XBZsSioaEaG3XBfrVr8ZKlbN+2te0wJElzXJL1/Vyaa8qLvs6klStWMDw83HYYkiRJs85hSkmSpBaZjEmSJLVoTgxTbhwZoftdl9JMcm6YJGkumRPJ2NjoKMtOv7jtMLRAbDljTdshSJL0nxymlCRJapHJmCRJUosmTcaSLE1yaZKrk2xKckpTvjLJN5JcmeTTSe7VlC9Kcm5TvjnJW2b6JiRJkuarqfSMjQGnVdVRwDHA65IcBXwQeHNVPRK4CHhTU/9E4O5N+aOAVydZ3u/AJUmSBsGkyVhVba+qK5rt24DNwBLgSOCyptolwPN3HQLsn2Rf4B7AncCtfY5bkiRpIOzVnLGmh+to4HJgE3BCs+tEYGmz/XHgdmA7sBV4V1Xd0odYJUmSBs6Uk7EkBwAXAKdW1a3AK4HXJlkPHEinBwzgMcBdwKHA4cBpSR48wfnWJhlO4nuQJEnSgjWldcaSLKKTiJ1XVRcCVNU1wNOa/UcCz2yq/zfg81U1CuxI8jVgNXBd9zmrah2wrjm+/beVS5IktWAqT1MGOAvYXFVndpUf0vx5N+CPgA80u7YCT2727U9n0v81/Q1bkiRpMExlmPJY4GTgyUk2NJ/jgZOSfIdOovVvwDlN/b8FDkiyCfgWcE5VjcxA7JIkSfPepMOUVfVVYHcvjnzPBPV/QmdCvyRJkibhCvySJEktMhmTJElqkcmYJElSi1LV/qoSi4aGamx0tO0wtEAsXrKU7du2th2GJGmeSrK+qlb363xTWmdspq1csYLhYdd+lSRJC4/DlJIkSS0yGZMkSWrRnBim3DgyQmehf2lmOE9MkjRXzYlkbGx0lGWnX9x2GBpgW85Y03YIkiRNyGFKSZKkFpmMSZIktainZCzJKUmuSrIpyalN2YnN951J+rYGhyRJ0iCadjKW5BHA7wKPAVYCa5L8CnAV8Dzgsr5EKEmSNMB66Rn7VeDyqvppVY0BXwGeV1Wbq+ra/oQnSZI02HpJxq4CjktyvyT3BI4HlvYnLEmSpIVh2ktbVNXmJGcAXwBuBzYAd031+CRrgbXTvb4kSdIg6GkCf1WdVVWPqqonAP8BfGcvjl1XVav7+aJNSZKk+aanRV+THFJVO5I8iM6k/WP6E5YkSdLC0OsK/BckuR8wCryuqn6U5LnA+4D7A59JsqGqnt5roJIkSYOop2Ssqo6boOwi4KJezitJkrRQuAK/JElSi0zGJEmSWmQyJkmS1KJUVdsxsGhoqMZGR9sOQwNs8ZKlbN+2te0wJEkDIMn6fi7N1evTlH2xcsUKhoeH2w5DkiRp1jlMKUmS1CKTMUmSpBbNiWHKjSMjJGk7DA0Q54hJkuaLOZGMjY2Osuz0i9sOQwNkyxlr2g5BkqQpcZhSkiSpRSZjkiRJLZo0GUuyNMmlSa5OsinJKU35yiTfSHJlkk8nuVdTvjzJz5JsaD4fmOmbkCRJmq+mMmdsDDitqq5IciCwPsklwAeBN1bVV5K8EngT8D+aY75XVatmJmRJkqTBMWnPWFVtr6ormu3bgM3AEuBI4LKm2iXA82cqSEmSpEG1V3PGkiwHjgYuBzYBJzS7TgSWdlU9PMm3k3wlyXF9iFOSJGkgTTkZS3IAcAFwalXdCrwSeG2S9cCBwJ1N1e3Ag6rqaOC/A/+4az7ZuPOtTTKcxPcgSZKkBWtK64wlWUQnETuvqi4EqKprgKc1+48EntmU3wHc0WyvT/I9OkOav5B0VdU6YF1zfPtvK5ckSWrBVJ6mDHAWsLmqzuwqP6T5827AHwEfaL7fP8k+zfaDgSOA6/ofuiRJ0vw3lZ6xY4GTgSuTbGjK3gockeR1zfcLgXOa7ScAf5pkFNgJvKaqbuljzJIkSQNj0mSsqr4K7O7Fke+ZoP4FdIY0JUmSNAlX4JckSWqRyZgkSVKLTMYkSZJalKr2V5VYNDRUY6OjbYehAbJ4yVK2b9vadhiSpAGUZH1Vre7X+aa0zthMW7liBcPDrv0qSZIWHocpJUmSWmQyJkmS1KI5MUy5cWSEzkL/Um+cKyZJmm/mRDI2NjrKstMvbjsMDYAtZ6xpOwRJkvaKw5SSJEktMhmTJElq0aTJWJKlSS5NcnWSTUlOacoPSnJJkv/b/Hnfpvy+SS5KMpLkm0keMdM3IUmSNF9NpWdsDDitqo4CjgFel+Qo4M3AF6vqCOCLzXeAtwIbqmoF8FImeJm4JEmSOiZNxqpqe1Vd0WzfBmwGlgAnAOc21c4FntNsHwV8qal/DbA8yQP6HLckSdJA2Ks5Y0mWA0cDlwMPqKrtza7vA7sSro3A85r6jwGWAYf1IVZJkqSBM+VkLMkBwAXAqVV1a/e+6rzgctdLLt8J3CfJBuD1wLeBuyY439okw0l8D5IkSVqwprTOWJJFdBKx86rqwqb4B0keWFXbkzwQ2AHQJGqvaI4LcD1w3fhzVtU6YF1Tr/23lUuSJLVgKk9TBjgL2FxVZ3bt+hTwsmb7ZcAnm/r3STLUlP8OcNn4njRJkiR1TKVn7FjgZODKZugROk9MvhP4WJJXAVuAFzb7fhU4t+nt2gS8qr8hS5IkDY5Jk7Gq+iqwuxdHPmWC+t8AjuwxLkmSpAXBFfglSZJaZDImSZLUIpMxSZKkFqWzRFi7Fg0N1djoaNthaAAsXrKU7du2th2GJGmAJVlfVav7db4prTM201auWMHwsGu/SpKkhcdhSkmSpBaZjEmSJLVoTgxTbhwZobPQvzR9zheTJM1HcyIZGxsdZdnpF7cdhua5LWesaTsESZL2msOUkiRJLTIZkyRJatGkyViSs5PsSHLVuPLXJ7kmyaYkfzlu34OS/CTJG/sdsCRJ0iCZSs/Yh4BndBckeRJwArCyqh4OvGvcMWcCn+tHgJIkSYNs0gn8VXVZkuXjin8PeGdV3dHU2bFrR5LnANcDt/cvTEmSpME03TljRwLHJbk8yVeSPBogyQHA6cCf9CtASZKkQTbdpS32BQ4CjgEeDXwsyYOBdwB/XVU/mWzdsCRrgbXTvL4kSdJAmG4ytg24sDpvGf9mkp3AwcBjgRc0E/rvA+xM8vOqev/4E1TVOmAdQJL231YuSZLUgukmY58AngRcmuRIYAi4uaqO21UhyTuAn0yUiEmSJKlj0mQsyfnAE4GDk2wD3g6cDZzdLHdxJ/CyppdMkiRJe2EqT1OetJtdvz3Jce+YTkCSJEkLiSvwS5IktchkTJIkqUUmY5IkSS3KXJh3v2hoqMZGR9sOQ/Pc4iVL2b5ta9thSJIGXJL1VbW6X+eb7tIWfbVyxQqGh4fbDkOSJGnWOUwpSZLUIpMxSZKkFs2JYcqNIyNM9i5LaSLOE5MkzXdzIhkbGx1l2ekXtx2G5qEtZ6xpOwRJknriMKUkSVKLTMYkSZJaNGkyluTsJDual4LvKluZ5BtJrkzy6ST3asqHkpzTlG9M8sQZjF2SJGnem0rP2IeAZ4wr+yDw5qp6JHAR8Kam/HcBmvKnAu9OYu+bJEnSbkyaKFXVZcAt44qPBC5rti8Bnt9sHwV8qTluB/AjoG8r1EqSJA2a6fZabQJOaLZPBJY22xuBZyfZN8nhwKO69kmSJGmc6SZjrwRem2Q9cCBwZ1N+NrANGAb+Bvg6cNdEJ0iyNslwEt+DJEmSFqxprTNWVdcATwNIciTwzKZ8DPiDXfWSfB34zm7OsQ5Y19Rr/23lkiRJLZhWz1iSQ5o/7wb8EfCB5vs9k+zfbD8VGKuqq/sUqyRJ0sCZtGcsyfnAE4GDk2wD3g4ckOR1TZULgXOa7UOAf06yE7gJOLnvEUuSJA2QSZOxqjppN7veM0HdG4CH9hiTJEnSguEaYJIkSS0yGZMkSWqRyZgkSVKLUtX+qhKLhoZqbHS07TA0Dy1espTt27a2HYYkaQFJsr6q+vaGoWmtM9ZvK1esYHjYtV8lSdLC4zClJElSi0zGJEmSWjQnhik3joyQpO0wNMc4H0yStBDMiWRsbHSUZadf3HYYmmO2nLGm7RAkSZpxDlNKkiS1yGRMkiSpRZMmY0mWJrk0ydVJNiU5pSn/qyTXJBlJclGS+zTlL0myoeuzM8mqmb4RSZKk+WgqPWNjwGlVdRRwDPC6JEcBlwCPqKoVwHeAtwBU1XlVtaqqVgEnA9dX1YaZCV+SJGl+mzQZq6rtVXVFs30bsBlYUlVfqKqxptq/AodNcPhJwEf6FawkSdKg2as5Y0mWA0cDl4/b9UrgcxMc8iLg/OkEJkmStBBMeWmLJAcAFwCnVtWtXeVvozOUed64+o8FflpVV+3mfGuBtdMJWpIkaVBMKRlLsohOInZeVV3YVf5yYA3wlPrlN46/mD30ilXVOmBdc57231YuSZLUgkmTsXSWxj8L2FxVZ3aVPwP4Q+A3quqn4465G/BC4Lj+hitJkjRYptIzdiydpyKvTLLrqci3Au8F7g5c0rzK6F+r6jXN/icAN1bVdX2OV5IkaaBMmoxV1VeBiV4c+dk9HPNlOstgSJIkaQ9cgV+SJKlFJmOSJEktMhmTJElqUX55RYrZt2hoqMZGR9sOQ3PM4iVL2b5ta9thSJL0C5Ksr6rV/TrflBd9nUkrV6xgeHi47TAkSZJmncOUkiRJLTIZkyRJatGcGKbcODJCs3CsFhDnhEmSNEeSsbHRUZadfnHbYWiWbTljTdshSJLUOocpJUmSWmQyJkmS1KJJk7EkZyfZkeSqrrI/SzKSZEOSLyQ5tCl/U1O2IclVSe5KctBM3oAkSdJ8NpWesQ8BzxhX9ldVtaKqVgEXA38MUFV/VVWrmvK3AF+pqlv6GbAkSdIgmTQZq6rLgFvGld3a9XV/YKJl/E8Czu8pOkmSpAE37acpk/w58FLgx8CTxu27J53etN/vKTpJkqQBN+0J/FX1tqpaCpzHLyddzwK+tqchyiRrkwwn8T1IkiRpwerH05TnAc8fV/ZiJhmirKp1VbW6ny/alCRJmm+mlYwlOaLr6wnANV377g38BvDJ3kKTJEkafJPOGUtyPvBE4OAk24C3A8cneSiwE9gCvKbrkOcCX6iq2/sfriRJ0mCZNBmrqpMmKD5rD/U/RGc5DEmSJE3CFfglSZJaZDImSZLUIpMxSZKkFqVqosXzZ9eioaEaGx1tOwzNssVLlrJ929a2w5Akaa8kWd/PpbmmvQJ/P61csYLhYdd+lSRJC4/DlJIkSS0yGZMkSWrRnBim3DgyQpK2w9Asc86YJElzJBkbGx1l2ekXtx2GZtmWM9a0HYIkSa1zmFKSJKlFJmOSJEktMhmTJElqUU/JWJIbklyZZEOS4a7y1ye5JsmmJH/Ze5iSJEmDqR8T+J9UVTfv+pLkScAJwMqquiPJIX24hiRJ0kCaiWHK3wPeWVV3AFTVjhm4hiRJ0kDoNRkr4AtJ1idZ25QdCRyX5PIkX0ny6IkOTLI2yXD38KYkSdJC0+sw5eOr6qZmKPKSJNc05zwIOAZ4NPCxJA+ucW8kr6p1wDqAJO2/rVySJKkFPfWMVdVNzZ87gIuAxwDbgAur45vATuDgXgOVJEkaRNNOxpLsn+TAXdvA04CrgE8AT2rKjwSGgJt3dx5JkqSFrJdhygcAFzXvlNwX+Meq+nySIeDsJFcBdwIvGz9EKUmSpI5pJ2NVdR2wcoKMB1mEAAAJuklEQVTyO4Hf7iUoSZKkhcIV+CVJklpkMiZJktSizIXpXIuGhmpsdLTtMDTLFi9ZyvZtW9sOQ5KkvZJkfVWt7tf5+vE6pJ6tXLGC4WHXfpUkSQuPw5SSJEktMhmTJElqkcmYJElSi0zGJEmSWmQyJkmS1CKTMUmSpBaZjEmSJLXIZEySJKlFJmOSJEktMhmTJElqkcmYJElSi0zGJEmSWmQyJkmS1KJUVdsxkOQ24Nq241hgDgZubjuIBcY2n322+eyzzWeX7T37Dgb2r6r79+uE+/brRD26tqpWtx3EQpJk2DafXbb57LPNZ59tPrts79nXtPnyfp7TYUpJkqQWmYxJkiS1aK4kY+vaDmABss1nn20++2zz2Webzy7be/b1vc3nxAR+SZKkhWqu9IxJkiQtSDOSjCV5RpJrk3w3yZsn2H/3JB9t9l+eZHnXvrc05dcmefpUz7nQzVCb35DkyiQbkgzPzp3MD9Nt7yT3S3Jpkp8kef+4Yx7VtPd3k7w3SWbnbuaHGWrzLzfn3NB8Dpmdu5kfemjzpyZZ3/ye1yd5ctcx/s73YIba3N/5HvTQ5o/patONSZ471XP+kqrq6wfYB/ge8GBgCNgIHDWuzmuBDzTbLwY+2mwf1dS/O3B4c559pnLOhfyZiTZv9t0AHNz2/c21T4/tvT/weOA1wPvHHfNN4BggwOeA32r7XufKZwbb/MvA6rbvby5+emzzo4FDm+1HADd1HePvfPbb3N/5zLT5PYF9m+0HAjvoLBm21znLTPSMPQb4blVdV1V3Ah8BThhX5wTg3Gb748BTmv87OgH4SFXdUVXXA99tzjeVcy5kM9Hm2r1pt3dV3V5VXwV+3l05yQOBe1XVv1bnv+y/B54zo3cxv/S9zTWpXtr821X1b035JuAeTe+Cv/M963ubz0rU81svbf7TqhpryvcDdk3C3+ucZSaSsSXAjV3ftzVlE9ZpbuTHwP32cOxUzrmQzUSbQ+eH9YWmy3vtDMQ9X/XS3ns657ZJzrmQzUSb73JOM8zwPxwy+wX9avPnA1dU1R34O5/MTLT5Lv7OJ9ZTmyd5bJJNwJXAa5r9e52zOIFfe/L4qvo14LeA1yV5QtsBSX32kqp6JHBc8zm55XgGSpKHA2cAr247loViN23u73yGVNXlVfVw4NHAW5LsN53zzEQydhOwtOv7YU3ZhHWS7AvcG/j3PRw7lXMuZDPR5lTVrj93ABfh8OUuvbT3ns552CTnXMhmos27f+O3Af+Iv/FuPbV5ksPo/Lvx0qr6Xld9f+e7NxNt7u98z/ryb0tVbQZ+QjNfbwrn/AUzkYx9CzgiyeFJhuhMdvvUuDqfAl7WbL8A+FIzf+BTwIubuQWHA0fQmew5lXMuZH1v8yT7JzkQIMn+wNOAq2bhXuaDXtp7QlW1Hbg1yTHNEMJLgU/2P/R5q+9tnmTfJAc324uANfgb7zbtNk9yH+AzwJur6mu7Kvs7n1Tf29zf+aR6afPDm+SMJMuAh9F58G3vc5YZejrheOA7dJ4meFtT9qfAs5vt/YB/ojNZ/JvAg7uOfVtz3LV0PWUz0Tn9zFyb03kKZGPz2WSb97W9bwBuofN/UdtonrIBVtP5R/J7wPtpFmX2MzNtTucpy/XASPMbfw/Nk8R+emtz4I+A24ENXZ9Dmn3+zmexzf2dz2ibn9y06QbgCuA5ezrnnj6uwC9JktQiJ/BLkiS1yGRMkiSpRSZjkiRJLTIZkyRJapHJmCRJUotMxqQFKkkleXfX9zcmeccsx/ChJC9otj+Y5Kgez7c8yS+tobS78pmUZFWS42fzmpLmJ5MxaeG6A3jergUh99auxQ77pap+p6qu7uc529K0zSo6aw1J0h719R9TSfPKGLAO+AM6C//+pyTLgbOBg4EfAq+oqq1JPgT8HDga+FqSW4HD6SwS/KDmXMfQeZ/pTcCzqmo0yR8DzwLuAXwdeHWNW+QwyZeBNwKH0llwkab+UFUdnuRRwJnAAcDNwMurantTfnZT/wuT3XSSlwPPobMY5hHAu4AhOgs43gEcX1W3NPFsBH6Dzr+Vr6yqbyY5qLneg4GfAmuraqTpVXxIU74VOBa4R5LHA38BXE9nwc39gJ81bXptE8+zgXs2x19UVX/YxPoM4P8H9gFurqqnNG/EeB+d164sAt5RVa5iL81j9oxJC9vfAi9Jcu9x5e8Dzq2qFcB5wHu79h0G/HpV/ffm+0OAJ9NJKD4MXFqdlxL/DHhmU+f9VfXoqnoEnQRrze4CqqpPVdWqqlpFJxl6V/Mal/cBL6iqXcnXnzeHnAO8vqpW7sV9PwJ4Hp2X+/458NOqOhr4Bp1X9OxyzyaO1/JfCd+fAN9u2uatwN931T8K+M2qOgn4Y+Cjzb18FLgGOK65zh/TSbJ2WQW8CHgk8KIkS5PcH/g74PnNvZ3Y1H0bndexPAZ4EvBXTYImaZ6yZ0xawKrq1iR/D7yBTvK0y+PoJCsA/wD8Zde+f6qqu7q+f67p/bqSTg/O55vyK4HlzfaTkvwhnd6fg+i8QuTTe4qtqf+zqvrbJI+gk0Bd0nmlIfsA25v38d2nqi7rivW3pnDrl1bnpcm3JflxVyxXAiu66p0PUFWXJblXc73HA89vyr+U5H5J7tXU/1RVdbdjt3sD5yY5Aig6vVq7fLGqftzc99XAMuC+wGVVdX1zrVuauk8Dnp3kjc33/ej0Sm6ewn1LmoNMxiT9DZ33qp0zxfq3j/t+B0BV7Uwy2jX8uBPYN8l+wP8EVlfVjc1w3n57ukCS36TTE/SEXUXApqp63Lh695lizOPd0bW9s+v7Tn7x38Xx74ub7P1x49um25/RSQKf2wwDf3k38dzFnv9tDp3esmsniUXSPOEwpbTANT0uHwNe1VX8deDFzfZLgH/p4RK7Eq+bkxwAvGBPlZMsozN8emJXL9O1wP2TPK6psyjJw6vqR8CPmnlZu2Ltpxc113s88OOm9+pfdl0nyRPpzOW6dYJjbwMO7Pp+bzrz6ABePoVr/yvwhCSHN9c6qCn/Z+D1aboIkxy9F/cjaQ4yGZME8G46k/V3eT3wiiQjdCa2nzLdEzcJ098BV9FJJL41ySEvB+4HfCLJhiSfrao76SRxZyTZCGwAfr2p/wrgb5NsoNNr1E8/T/Jt4AP8V7L6DuBRTdu8E3jZbo69FDiquYcX0Rnq/YvmfJOOSlTVD4G1wIXNPX+02fVndIY4R5Jsar5Lmscy7oEmSRL/9XRnVQ23HYukwWbPmCRJUovsGZMkSWqRPWOSJEktMhmTJElqkcmYJElSi0zGJEmSWmQyJkmS1CKTMUmSpBb9P5wJmm257fVqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_feature_importances(df):\n",
    "    #Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    #Normalise the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "    \n",
    "    #Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10,6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    #Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:15]))),\n",
    "           df['importance_normalized'].head(15),\n",
    "           align = 'center', edgecolor = 'k')\n",
    "    #Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "    ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "    #Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importance')\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "feature_importances_sorted = plot_feature_importances(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['33' '65' '24' '217' '117' '201' '298' '91' '295' '209' '164' '199' '227'\n",
      " '137' '56' '268' '214' '43' '144' '80' '189' '266' '139' '48' '230' '111'\n",
      " '26' '225' '275' '237' '207' '19' '123' '228' '165' '82' '276' '250'\n",
      " '277' '73' '192' '265' '272' '116' '289' '255' '17' '94' '7' '0' '119'\n",
      " '156' '12' '131' '285' '169' '147' '242' '247' '16' '170' '149' '240'\n",
      " '234' '291' '252' '89' '279' '195' '138' '13' '166' '47' '127' '52' '120'\n",
      " '288' '18' '148' '208' '141' '130' '155' '180' '51' '44' '101' '129' '23'\n",
      " '113' '37' '150' '132' '173' '202' '76' '239' '58' '163' '257' '215'\n",
      " '221' '40' '292' '284' '108' '226' '135' '4' '97' '9' '39' '191' '145'\n",
      " '77' '96' '11' '194' '152' '267' '204' '53' '66' '142' '259' '27' '30'\n",
      " '160' '231' '270' '98' '248' '42' '8' '278' '110' '185' '114' '256' '153'\n",
      " '206' '14' '238' '1' '271' '220' '84' '280' '106' '198' '162' '178' '100'\n",
      " '134' '258' '161' '253' '246' '154' '29' '62' '177' '68' '286' '67' '83'\n",
      " '200' '236' '78' '122' '118' '21' '171' '151' '197' '86' '70' '72' '283'\n",
      " '109' '38' '85' '103' '282' '175' '32' '74' '269' '244' '205' '287' '6'\n",
      " '45' '121' '90' '69' '203' '55' '264' '25' '167' '183' '95' '243' '105'\n",
      " '63' '281' '186' '140' '262' '211' '235' '213' '49' '88' '157' '294'\n",
      " '251' '249' '158' '92' '46' '187' '102' '179' '299' '104' '133' '87'\n",
      " '245' '273' '15' '168' '181' '35' '196' '60' '233' '2' '61' '54' '22'\n",
      " '188' '176' '223' '5' '193' '263' '218' '59' '224' '34' '232' '41' '128'\n",
      " '212' '174' '71' '172' '75' '293' '241' '50' '143' '31' '219' '229' '159'\n",
      " '125' '296' '126' '222' '254' '64' '190' '81' '93' '3' '261' '107' '297'\n",
      " '57' '20' '112' '136' '260' '216' '79']\n"
     ]
    }
   ],
   "source": [
    "fe_threshold = 0.001\n",
    "selected_features = feature_importances_sorted.query('importance_normalized > {}'.format(fe_threshold))['feature'].values\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_column ='target'\n",
    "#id_column = 'id'\n",
    "#categorical_cols = [c for c in train_input.columns if train_input[c].dtype in [np.object]]\n",
    "#numerical_cols = [c for c in train_input.columns if train_input[c].dtype in [np.float, np.int] and c not in [target_column, id_column]]\n",
    "#preprocess = make_column_transformer(\n",
    "#    (numerical_cols, make_pipeline(SimpleImputer(), StandardScaler())),\n",
    "#    (categorical_cols, OneHotEncoder()))\n",
    "#train_input = preprocess.fit_transform(train_input)\n",
    "#test_input = preprocess.fit_transform(test_input)\n",
    "#print(type(train_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = pd.DataFrame()\n",
    "selected_test = pd.DataFrame()\n",
    "for col in selected_features:\n",
    "    selected_df[col] = train_df[col]\n",
    "    selected_test[col] = test_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_, train_, target_):\n",
    "    \n",
    "    clfs = []\n",
    "    folds = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 20, random_state = 42)\n",
    "    \n",
    "    valid_pred = pd.DataFrame(index = train_.index)\n",
    "    \n",
    "    # Cross-validation cycle\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(target_, target_)):\n",
    "        print('--- Fold {} started at {}'.format(n_fold, time.ctime()))\n",
    "        \n",
    "        train_x, train_y = train_.iloc[train_idx], target_.iloc[train_idx]\n",
    "        valid_x, valid_y = train_.iloc[valid_idx], target_.iloc[valid_idx]\n",
    "        \n",
    "        \n",
    "        model_.fit(train_x, train_y)\n",
    "    \n",
    "        clfs.append(model_)\n",
    "\n",
    "        predict = model_.predict_proba(valid_x)[:, 1]\n",
    "    \n",
    "        tn, fp, fn, tp = confusion_matrix(valid_y, (predict >= .5) * 1).ravel()\n",
    "        auc = roc_auc_score(valid_y, predict)\n",
    "        acc = accuracy_score(valid_y, (predict >= .5) * 1)\n",
    "        loss = log_loss(valid_y, predict)\n",
    "        print('TN =', tn, 'FN =', fn, 'FP =', fp, 'TP =', tp)\n",
    "        print('AUC = ', auc, 'Loss =', loss, 'Acc =', acc)\n",
    "        \n",
    "        valid_pred[n_fold] = pd.Series(predict, index = valid_x.index)\n",
    "\n",
    "        del train_x, train_y, valid_x, valid_y, predict\n",
    "        gc.collect()\n",
    "\n",
    "    return clfs, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "\"model_lgbm\" : LGBMClassifier(n_jobs=-1,eta=0.01,max_depth=5,max_bin=512,learning_rate=0.01,num_iterations=1000),\n",
    "\"model_xgb\" : XGBClassifier(n_jobs=-1, nthreads=-1),\n",
    "\"model_lr\" : LogisticRegression(n_jobs=-1, penalty='l1', C=0.2, class_weight='balanced', solver='saga'),\n",
    "\"model_gnb\" : GaussianNB(),\n",
    "\"model_rf\" : RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitted_models_and_preds(df, labels, models):\n",
    "    ret =[]\n",
    "    for k,v in models.items():\n",
    "        clfs, pred = cross_validation(v, df, labels)\n",
    "        \n",
    "        ret.append({'classifier':k, 'score':pred.mean(axis=1), 'preds':pred.mean(axis=1), 'model': clfs})\n",
    "        print(\"model {}: {}\".format(k,pred.mean(axis=1)))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_models(df, fitted_base_models):\n",
    "    ret_df = pd.DataFrame()\n",
    "    \n",
    "    for fitted_base_model in fitted_base_models:\n",
    "        classifier = fitted_base_model['classifier']\n",
    "        preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        for model in fitted_base_model['model']:\n",
    "            predict = model.predict_proba(df)\n",
    "            print(predict[:,1])\n",
    "            preds[classifier + \"_\" + str(i)] = predict[:,1]\n",
    "            i+=1\n",
    "        pred = preds.mean(axis=1)\n",
    "        print(pred)\n",
    "        ret_df[classifier] = pred\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 0 started at Tue Apr 23 14:25:16 2019\n",
      "TN = 8 FN = 7 FP = 10 TP = 25\n",
      "AUC =  0.7135416666666667 Loss = 0.7130333960270065 Acc = 0.66\n",
      "--- Fold 1 started at Tue Apr 23 14:25:17 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.6996527777777778 Loss = 0.6688204057958184 Acc = 0.7\n",
      "--- Fold 2 started at Tue Apr 23 14:25:18 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.6215277777777777 Loss = 0.8225796916493348 Acc = 0.68\n",
      "--- Fold 3 started at Tue Apr 23 14:25:18 2019\n",
      "TN = 6 FN = 2 FP = 12 TP = 30\n",
      "AUC =  0.8003472222222223 Loss = 0.6455538705979295 Acc = 0.72\n",
      "--- Fold 4 started at Tue Apr 23 14:25:19 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.6892361111111112 Loss = 0.722543360587448 Acc = 0.64\n",
      "--- Fold 5 started at Tue Apr 23 14:25:20 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.7135416666666667 Loss = 0.6617380031970035 Acc = 0.66\n",
      "--- Fold 6 started at Tue Apr 23 14:25:20 2019\n",
      "TN = 5 FN = 8 FP = 13 TP = 24\n",
      "AUC =  0.5625 Loss = 0.9942820625109833 Acc = 0.58\n",
      "--- Fold 7 started at Tue Apr 23 14:25:21 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.6458333333333333 Loss = 0.8224104517821432 Acc = 0.64\n",
      "--- Fold 8 started at Tue Apr 23 14:25:22 2019\n",
      "TN = 10 FN = 4 FP = 8 TP = 28\n",
      "AUC =  0.6614583333333334 Loss = 0.7785880973460095 Acc = 0.76\n",
      "--- Fold 9 started at Tue Apr 23 14:25:23 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.7361111111111112 Loss = 0.6255759906916485 Acc = 0.7\n",
      "--- Fold 10 started at Tue Apr 23 14:25:24 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.7881944444444444 Loss = 0.6025950177583065 Acc = 0.68\n",
      "--- Fold 11 started at Tue Apr 23 14:25:27 2019\n",
      "TN = 7 FN = 2 FP = 11 TP = 30\n",
      "AUC =  0.7083333333333333 Loss = 0.7454508510323267 Acc = 0.74\n",
      "--- Fold 12 started at Tue Apr 23 14:25:33 2019\n",
      "TN = 11 FN = 6 FP = 7 TP = 26\n",
      "AUC =  0.7881944444444444 Loss = 0.5904057996448782 Acc = 0.74\n",
      "--- Fold 13 started at Tue Apr 23 14:25:35 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.7899305555555556 Loss = 0.5860791618610415 Acc = 0.74\n",
      "--- Fold 14 started at Tue Apr 23 14:25:36 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.751736111111111 Loss = 0.5979902101144701 Acc = 0.7\n",
      "--- Fold 15 started at Tue Apr 23 14:25:37 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.6805555555555556 Loss = 0.7277144095296957 Acc = 0.7\n",
      "--- Fold 16 started at Tue Apr 23 14:25:38 2019\n",
      "TN = 9 FN = 7 FP = 9 TP = 25\n",
      "AUC =  0.732638888888889 Loss = 0.6677057734882905 Acc = 0.68\n",
      "--- Fold 17 started at Tue Apr 23 14:25:39 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.6805555555555556 Loss = 0.7180684726306538 Acc = 0.7\n",
      "--- Fold 18 started at Tue Apr 23 14:25:40 2019\n",
      "TN = 8 FN = 7 FP = 10 TP = 25\n",
      "AUC =  0.7065972222222221 Loss = 0.6518789730976289 Acc = 0.66\n",
      "--- Fold 19 started at Tue Apr 23 14:25:41 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.7204861111111112 Loss = 0.6816689740430992 Acc = 0.66\n",
      "--- Fold 20 started at Tue Apr 23 14:25:42 2019\n",
      "TN = 7 FN = 7 FP = 11 TP = 25\n",
      "AUC =  0.6666666666666667 Loss = 0.7772437375587805 Acc = 0.64\n",
      "--- Fold 21 started at Tue Apr 23 14:25:43 2019\n",
      "TN = 4 FN = 2 FP = 14 TP = 30\n",
      "AUC =  0.7239583333333334 Loss = 0.6746344336430983 Acc = 0.68\n",
      "--- Fold 22 started at Tue Apr 23 14:25:44 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.6319444444444445 Loss = 0.9213370470693062 Acc = 0.64\n",
      "--- Fold 23 started at Tue Apr 23 14:25:45 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.7760416666666666 Loss = 0.6195168414313535 Acc = 0.68\n",
      "--- Fold 24 started at Tue Apr 23 14:25:46 2019\n",
      "TN = 8 FN = 9 FP = 10 TP = 23\n",
      "AUC =  0.6076388888888888 Loss = 0.8216881036507511 Acc = 0.62\n",
      "--- Fold 25 started at Tue Apr 23 14:25:46 2019\n",
      "TN = 6 FN = 6 FP = 12 TP = 26\n",
      "AUC =  0.6163194444444444 Loss = 0.8525005207893809 Acc = 0.64\n",
      "--- Fold 26 started at Tue Apr 23 14:25:47 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.6944444444444444 Loss = 0.6631386708769285 Acc = 0.68\n",
      "--- Fold 27 started at Tue Apr 23 14:25:48 2019\n",
      "TN = 6 FN = 2 FP = 12 TP = 30\n",
      "AUC =  0.6614583333333334 Loss = 0.7062727423145632 Acc = 0.72\n",
      "--- Fold 28 started at Tue Apr 23 14:25:49 2019\n",
      "TN = 9 FN = 1 FP = 9 TP = 31\n",
      "AUC =  0.8611111111111112 Loss = 0.4832616763910275 Acc = 0.8\n",
      "--- Fold 29 started at Tue Apr 23 14:25:50 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.6892361111111112 Loss = 0.7713360058515952 Acc = 0.66\n",
      "--- Fold 30 started at Tue Apr 23 14:25:51 2019\n",
      "TN = 2 FN = 7 FP = 16 TP = 25\n",
      "AUC =  0.6597222222222223 Loss = 0.6983551995609338 Acc = 0.54\n",
      "--- Fold 31 started at Tue Apr 23 14:25:52 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.6979166666666667 Loss = 0.8037679894197142 Acc = 0.64\n",
      "--- Fold 32 started at Tue Apr 23 14:25:53 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.7152777777777778 Loss = 0.7412590282804764 Acc = 0.66\n",
      "--- Fold 33 started at Tue Apr 23 14:25:53 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.6875 Loss = 0.7612578706642309 Acc = 0.68\n",
      "--- Fold 34 started at Tue Apr 23 14:25:54 2019\n",
      "TN = 11 FN = 3 FP = 7 TP = 29\n",
      "AUC =  0.8663194444444444 Loss = 0.42560601204129817 Acc = 0.8\n",
      "--- Fold 35 started at Tue Apr 23 14:25:55 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.7482638888888888 Loss = 0.6094079218311846 Acc = 0.72\n",
      "--- Fold 36 started at Tue Apr 23 14:25:56 2019\n",
      "TN = 8 FN = 2 FP = 10 TP = 30\n",
      "AUC =  0.8055555555555556 Loss = 0.5508309369449512 Acc = 0.76\n",
      "--- Fold 37 started at Tue Apr 23 14:25:57 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.6701388888888888 Loss = 0.7997547965314227 Acc = 0.68\n",
      "--- Fold 38 started at Tue Apr 23 14:25:58 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.6423611111111112 Loss = 0.8180397080372954 Acc = 0.7\n",
      "--- Fold 39 started at Tue Apr 23 14:25:59 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.7291666666666666 Loss = 0.7065737840369196 Acc = 0.72\n",
      "--- Fold 40 started at Tue Apr 23 14:26:00 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.6996527777777778 Loss = 0.7945383164229181 Acc = 0.68\n",
      "--- Fold 41 started at Tue Apr 23 14:26:00 2019\n",
      "TN = 10 FN = 1 FP = 8 TP = 31\n",
      "AUC =  0.7829861111111112 Loss = 0.5258679424097628 Acc = 0.82\n",
      "--- Fold 42 started at Tue Apr 23 14:26:01 2019\n",
      "TN = 9 FN = 7 FP = 9 TP = 25\n",
      "AUC =  0.6684027777777779 Loss = 0.8075821367080099 Acc = 0.68\n",
      "--- Fold 43 started at Tue Apr 23 14:26:02 2019\n",
      "TN = 7 FN = 0 FP = 11 TP = 32\n",
      "AUC =  0.7413194444444444 Loss = 0.6556592470833548 Acc = 0.78\n",
      "--- Fold 44 started at Tue Apr 23 14:26:03 2019\n",
      "TN = 8 FN = 2 FP = 10 TP = 30\n",
      "AUC =  0.828125 Loss = 0.5146443800744573 Acc = 0.76\n",
      "--- Fold 45 started at Tue Apr 23 14:26:04 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.7135416666666666 Loss = 0.6846977845172897 Acc = 0.64\n",
      "--- Fold 46 started at Tue Apr 23 14:26:05 2019\n",
      "TN = 4 FN = 8 FP = 14 TP = 24\n",
      "AUC =  0.5763888888888888 Loss = 0.9191521110116782 Acc = 0.56\n",
      "--- Fold 47 started at Tue Apr 23 14:26:06 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.7864583333333334 Loss = 0.6186641220437192 Acc = 0.68\n",
      "--- Fold 48 started at Tue Apr 23 14:26:06 2019\n",
      "TN = 11 FN = 4 FP = 7 TP = 28\n",
      "AUC =  0.8385416666666666 Loss = 0.4715037141688633 Acc = 0.78\n",
      "--- Fold 49 started at Tue Apr 23 14:26:07 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.6145833333333333 Loss = 0.9267154334159987 Acc = 0.64\n",
      "--- Fold 50 started at Tue Apr 23 14:26:08 2019\n",
      "TN = 6 FN = 2 FP = 12 TP = 30\n",
      "AUC =  0.6875 Loss = 0.7337124615131022 Acc = 0.72\n",
      "--- Fold 51 started at Tue Apr 23 14:26:09 2019\n",
      "TN = 5 FN = 6 FP = 13 TP = 26\n",
      "AUC =  0.5833333333333333 Loss = 0.9337762675081148 Acc = 0.62\n",
      "--- Fold 52 started at Tue Apr 23 14:26:10 2019\n",
      "TN = 6 FN = 10 FP = 12 TP = 22\n",
      "AUC =  0.5434027777777778 Loss = 0.9924274355059478 Acc = 0.56\n",
      "--- Fold 53 started at Tue Apr 23 14:26:11 2019\n",
      "TN = 10 FN = 4 FP = 8 TP = 28\n",
      "AUC =  0.8159722222222222 Loss = 0.5539409185138012 Acc = 0.76\n",
      "--- Fold 54 started at Tue Apr 23 14:26:12 2019\n",
      "TN = 10 FN = 1 FP = 8 TP = 31\n",
      "AUC =  0.8663194444444444 Loss = 0.45391636437258565 Acc = 0.82\n",
      "--- Fold 55 started at Tue Apr 23 14:26:12 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.7222222222222222 Loss = 0.7012630581774579 Acc = 0.7\n",
      "--- Fold 56 started at Tue Apr 23 14:26:13 2019\n",
      "TN = 8 FN = 4 FP = 10 TP = 28\n",
      "AUC =  0.7621527777777778 Loss = 0.6038696106803335 Acc = 0.72\n",
      "--- Fold 57 started at Tue Apr 23 14:26:14 2019\n",
      "TN = 5 FN = 10 FP = 13 TP = 22\n",
      "AUC =  0.5746527777777778 Loss = 1.0089212461886587 Acc = 0.54\n",
      "--- Fold 58 started at Tue Apr 23 14:26:15 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.7048611111111112 Loss = 0.6789000300525723 Acc = 0.68\n",
      "--- Fold 59 started at Tue Apr 23 14:26:16 2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.7760416666666666 Loss = 0.5692123861302281 Acc = 0.74\n",
      "--- Fold 60 started at Tue Apr 23 14:26:17 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.7638888888888888 Loss = 0.604562049517719 Acc = 0.7\n",
      "--- Fold 61 started at Tue Apr 23 14:26:18 2019\n",
      "TN = 4 FN = 7 FP = 14 TP = 25\n",
      "AUC =  0.5833333333333334 Loss = 0.8919997947218034 Acc = 0.58\n",
      "--- Fold 62 started at Tue Apr 23 14:26:19 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.6996527777777778 Loss = 0.7858677616235242 Acc = 0.68\n",
      "--- Fold 63 started at Tue Apr 23 14:26:19 2019\n",
      "TN = 8 FN = 1 FP = 10 TP = 31\n",
      "AUC =  0.7690972222222222 Loss = 0.5883622667729292 Acc = 0.78\n",
      "--- Fold 64 started at Tue Apr 23 14:26:20 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.71875 Loss = 0.6626816391507162 Acc = 0.66\n",
      "--- Fold 65 started at Tue Apr 23 14:26:21 2019\n",
      "TN = 5 FN = 1 FP = 13 TP = 31\n",
      "AUC =  0.7986111111111112 Loss = 0.5829307399906907 Acc = 0.72\n",
      "--- Fold 66 started at Tue Apr 23 14:26:22 2019\n",
      "TN = 4 FN = 6 FP = 14 TP = 26\n",
      "AUC =  0.6354166666666666 Loss = 0.852031081855648 Acc = 0.6\n",
      "--- Fold 67 started at Tue Apr 23 14:26:23 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.6979166666666667 Loss = 0.6498938445294117 Acc = 0.68\n",
      "--- Fold 68 started at Tue Apr 23 14:26:24 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.6979166666666666 Loss = 0.7742036260752556 Acc = 0.7\n",
      "--- Fold 69 started at Tue Apr 23 14:26:25 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.6909722222222223 Loss = 0.7041397086721074 Acc = 0.7\n",
      "--- Fold 70 started at Tue Apr 23 14:26:25 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.7291666666666666 Loss = 0.6544295779474781 Acc = 0.68\n",
      "--- Fold 71 started at Tue Apr 23 14:26:26 2019\n",
      "TN = 9 FN = 1 FP = 9 TP = 31\n",
      "AUC =  0.8159722222222222 Loss = 0.5236123334416145 Acc = 0.8\n",
      "--- Fold 72 started at Tue Apr 23 14:26:27 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.765625 Loss = 0.611658774561225 Acc = 0.7\n",
      "--- Fold 73 started at Tue Apr 23 14:26:28 2019\n",
      "TN = 7 FN = 9 FP = 11 TP = 23\n",
      "AUC =  0.6284722222222222 Loss = 0.8162186792799621 Acc = 0.6\n",
      "--- Fold 74 started at Tue Apr 23 14:26:29 2019\n",
      "TN = 3 FN = 6 FP = 15 TP = 26\n",
      "AUC =  0.5989583333333334 Loss = 0.9394359042592619 Acc = 0.58\n",
      "--- Fold 75 started at Tue Apr 23 14:26:30 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.7204861111111112 Loss = 0.7267079299057851 Acc = 0.66\n",
      "--- Fold 76 started at Tue Apr 23 14:26:31 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.8246527777777778 Loss = 0.495745758577077 Acc = 0.72\n",
      "--- Fold 77 started at Tue Apr 23 14:26:31 2019\n",
      "TN = 6 FN = 2 FP = 12 TP = 30\n",
      "AUC =  0.7621527777777778 Loss = 0.6187023915102031 Acc = 0.72\n",
      "--- Fold 78 started at Tue Apr 23 14:26:32 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.6979166666666667 Loss = 0.7164459429675054 Acc = 0.7\n",
      "--- Fold 79 started at Tue Apr 23 14:26:33 2019\n",
      "TN = 9 FN = 2 FP = 9 TP = 30\n",
      "AUC =  0.767361111111111 Loss = 0.6061458343131768 Acc = 0.78\n",
      "--- Fold 80 started at Tue Apr 23 14:26:34 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.7795138888888888 Loss = 0.6101870367163699 Acc = 0.66\n",
      "--- Fold 81 started at Tue Apr 23 14:26:35 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.6649305555555556 Loss = 0.7623720470431025 Acc = 0.74\n",
      "--- Fold 82 started at Tue Apr 23 14:26:36 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.7430555555555556 Loss = 0.6576466121467466 Acc = 0.72\n",
      "--- Fold 83 started at Tue Apr 23 14:26:36 2019\n",
      "TN = 10 FN = 4 FP = 8 TP = 28\n",
      "AUC =  0.7274305555555556 Loss = 0.6603205973306191 Acc = 0.76\n",
      "--- Fold 84 started at Tue Apr 23 14:26:37 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.6684027777777777 Loss = 0.7454369682096913 Acc = 0.64\n",
      "--- Fold 85 started at Tue Apr 23 14:26:38 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.7065972222222223 Loss = 0.7255794724970602 Acc = 0.68\n",
      "--- Fold 86 started at Tue Apr 23 14:26:39 2019\n",
      "TN = 9 FN = 2 FP = 9 TP = 30\n",
      "AUC =  0.765625 Loss = 0.611972852865878 Acc = 0.78\n",
      "--- Fold 87 started at Tue Apr 23 14:26:40 2019\n",
      "TN = 12 FN = 7 FP = 6 TP = 25\n",
      "AUC =  0.7135416666666665 Loss = 0.6953885168704432 Acc = 0.74\n",
      "--- Fold 88 started at Tue Apr 23 14:26:41 2019\n",
      "TN = 4 FN = 5 FP = 14 TP = 27\n",
      "AUC =  0.6649305555555556 Loss = 0.7482339844703212 Acc = 0.62\n",
      "--- Fold 89 started at Tue Apr 23 14:26:42 2019\n",
      "TN = 10 FN = 7 FP = 8 TP = 25\n",
      "AUC =  0.7725694444444444 Loss = 0.575833146042263 Acc = 0.7\n",
      "--- Fold 90 started at Tue Apr 23 14:26:42 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.71875 Loss = 0.7238749347343051 Acc = 0.7\n",
      "--- Fold 91 started at Tue Apr 23 14:26:43 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.6215277777777778 Loss = 0.816543338727077 Acc = 0.64\n",
      "--- Fold 92 started at Tue Apr 23 14:26:44 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.736111111111111 Loss = 0.7131220740400839 Acc = 0.7\n",
      "--- Fold 93 started at Tue Apr 23 14:26:45 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.7256944444444444 Loss = 0.6369777491306542 Acc = 0.7\n",
      "--- Fold 94 started at Tue Apr 23 14:26:46 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.638888888888889 Loss = 0.8829471366175997 Acc = 0.7\n",
      "--- Fold 95 started at Tue Apr 23 14:26:47 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.6631944444444444 Loss = 0.7349063177226104 Acc = 0.68\n",
      "--- Fold 96 started at Tue Apr 23 14:26:47 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.7430555555555556 Loss = 0.6427158278101605 Acc = 0.7\n",
      "--- Fold 97 started at Tue Apr 23 14:26:48 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.7395833333333333 Loss = 0.7221242408710872 Acc = 0.66\n",
      "--- Fold 98 started at Tue Apr 23 14:26:49 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.7586805555555556 Loss = 0.6420533783334806 Acc = 0.68\n",
      "--- Fold 99 started at Tue Apr 23 14:26:50 2019\n",
      "TN = 11 FN = 4 FP = 7 TP = 28\n",
      "AUC =  0.8333333333333334 Loss = 0.5167705921835892 Acc = 0.78\n",
      "model model_lgbm: 0      0.861938\n",
      "1      0.728672\n",
      "2      0.959275\n",
      "3      0.751621\n",
      "4      0.877490\n",
      "5      0.939043\n",
      "6      0.512007\n",
      "7      0.828575\n",
      "8      0.723102\n",
      "9      0.672103\n",
      "10     0.483352\n",
      "11     0.718771\n",
      "12     0.893299\n",
      "13     0.379347\n",
      "14     0.737820\n",
      "15     0.987405\n",
      "16     0.986544\n",
      "17     0.831766\n",
      "18     0.990459\n",
      "19     0.866362\n",
      "20     0.957578\n",
      "21     0.904443\n",
      "22     0.148179\n",
      "23     0.226278\n",
      "24     0.486220\n",
      "25     0.811947\n",
      "26     0.834591\n",
      "27     0.917633\n",
      "28     0.918853\n",
      "29     0.695549\n",
      "         ...   \n",
      "220    0.853767\n",
      "221    0.835861\n",
      "222    0.903637\n",
      "223    0.749494\n",
      "224    0.872208\n",
      "225    0.587045\n",
      "226    0.967773\n",
      "227    0.165565\n",
      "228    0.940620\n",
      "229    0.980470\n",
      "230    0.646312\n",
      "231    0.943930\n",
      "232    0.960331\n",
      "233    0.533350\n",
      "234    0.504841\n",
      "235    0.647947\n",
      "236    0.888039\n",
      "237    0.823421\n",
      "238    0.879344\n",
      "239    0.636888\n",
      "240    0.231497\n",
      "241    0.649095\n",
      "242    0.691112\n",
      "243    0.960029\n",
      "244    0.763420\n",
      "245    0.657070\n",
      "246    0.624518\n",
      "247    0.929856\n",
      "248    0.587686\n",
      "249    0.203152\n",
      "Length: 250, dtype: float64\n",
      "--- Fold 0 started at Tue Apr 23 14:26:51 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.7743055555555556 Loss = 0.5887404823116958 Acc = 0.66\n",
      "--- Fold 1 started at Tue Apr 23 14:26:51 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7065972222222222 Loss = 0.6434513008780778 Acc = 0.72\n",
      "--- Fold 2 started at Tue Apr 23 14:26:51 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.6319444444444445 Loss = 0.7622615931928158 Acc = 0.68\n",
      "--- Fold 3 started at Tue Apr 23 14:26:51 2019\n",
      "TN = 3 FN = 2 FP = 15 TP = 30\n",
      "AUC =  0.810763888888889 Loss = 0.57952651290223 Acc = 0.66\n",
      "--- Fold 4 started at Tue Apr 23 14:26:51 2019\n",
      "TN = 4 FN = 5 FP = 14 TP = 27\n",
      "AUC =  0.7378472222222222 Loss = 0.6295878690201789 Acc = 0.62\n",
      "--- Fold 5 started at Tue Apr 23 14:26:52 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.7829861111111112 Loss = 0.5435823784768581 Acc = 0.66\n",
      "--- Fold 6 started at Tue Apr 23 14:26:52 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.6388888888888888 Loss = 0.7455121541488916 Acc = 0.68\n",
      "--- Fold 7 started at Tue Apr 23 14:26:52 2019\n",
      "TN = 4 FN = 5 FP = 14 TP = 27\n",
      "AUC =  0.6371527777777778 Loss = 0.7165167064126581 Acc = 0.62\n",
      "--- Fold 8 started at Tue Apr 23 14:26:52 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.6736111111111112 Loss = 0.6453620790690183 Acc = 0.72\n",
      "--- Fold 9 started at Tue Apr 23 14:26:52 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.7118055555555556 Loss = 0.6053982279077172 Acc = 0.66\n",
      "--- Fold 10 started at Tue Apr 23 14:26:52 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.5902777777777778 Loss = 0.7569844465143979 Acc = 0.66\n",
      "--- Fold 11 started at Tue Apr 23 14:26:53 2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.6944444444444444 Loss = 0.6672649435698986 Acc = 0.66\n",
      "--- Fold 12 started at Tue Apr 23 14:26:53 2019\n",
      "TN = 12 FN = 4 FP = 6 TP = 28\n",
      "AUC =  0.7690972222222222 Loss = 0.5955405669100583 Acc = 0.8\n",
      "--- Fold 13 started at Tue Apr 23 14:26:53 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.75 Loss = 0.6111386968754232 Acc = 0.72\n",
      "--- Fold 14 started at Tue Apr 23 14:26:53 2019\n",
      "TN = 8 FN = 2 FP = 10 TP = 30\n",
      "AUC =  0.6961805555555556 Loss = 0.6032161815464496 Acc = 0.76\n",
      "--- Fold 15 started at Tue Apr 23 14:26:53 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.6614583333333333 Loss = 0.6990377793833613 Acc = 0.68\n",
      "--- Fold 16 started at Tue Apr 23 14:26:53 2019\n",
      "TN = 11 FN = 7 FP = 7 TP = 25\n",
      "AUC =  0.7604166666666667 Loss = 0.5729863368719816 Acc = 0.72\n",
      "--- Fold 17 started at Tue Apr 23 14:26:54 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.7274305555555556 Loss = 0.5992094673588872 Acc = 0.64\n",
      "--- Fold 18 started at Tue Apr 23 14:26:54 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.7638888888888888 Loss = 0.5415027780458331 Acc = 0.68\n",
      "--- Fold 19 started at Tue Apr 23 14:26:54 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.71875 Loss = 0.640642274999991 Acc = 0.68\n",
      "--- Fold 20 started at Tue Apr 23 14:26:54 2019\n",
      "TN = 10 FN = 5 FP = 8 TP = 27\n",
      "AUC =  0.7083333333333333 Loss = 0.6219482142385095 Acc = 0.74\n",
      "--- Fold 21 started at Tue Apr 23 14:26:54 2019\n",
      "TN = 6 FN = 6 FP = 12 TP = 26\n",
      "AUC =  0.734375 Loss = 0.5991052422486246 Acc = 0.64\n",
      "--- Fold 22 started at Tue Apr 23 14:26:54 2019\n",
      "TN = 4 FN = 5 FP = 14 TP = 27\n",
      "AUC =  0.6666666666666666 Loss = 0.7265492494404316 Acc = 0.62\n",
      "--- Fold 23 started at Tue Apr 23 14:26:55 2019\n",
      "TN = 8 FN = 4 FP = 10 TP = 28\n",
      "AUC =  0.7204861111111112 Loss = 0.6196627711877227 Acc = 0.72\n",
      "--- Fold 24 started at Tue Apr 23 14:26:55 2019\n",
      "TN = 7 FN = 7 FP = 11 TP = 25\n",
      "AUC =  0.5850694444444444 Loss = 0.7314180944487453 Acc = 0.64\n",
      "--- Fold 25 started at Tue Apr 23 14:26:55 2019\n",
      "TN = 8 FN = 8 FP = 10 TP = 24\n",
      "AUC =  0.6302083333333334 Loss = 0.7405687419138849 Acc = 0.64\n",
      "--- Fold 26 started at Tue Apr 23 14:26:55 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.7222222222222222 Loss = 0.5999390804395079 Acc = 0.66\n",
      "--- Fold 27 started at Tue Apr 23 14:26:55 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.6736111111111112 Loss = 0.6579267626814544 Acc = 0.66\n",
      "--- Fold 28 started at Tue Apr 23 14:26:55 2019\n",
      "TN = 4 FN = 1 FP = 14 TP = 31\n",
      "AUC =  0.8177083333333334 Loss = 0.5243000593967736 Acc = 0.7\n",
      "--- Fold 29 started at Tue Apr 23 14:26:56 2019\n",
      "TN = 7 FN = 2 FP = 11 TP = 30\n",
      "AUC =  0.8402777777777778 Loss = 0.5269680783525109 Acc = 0.74\n",
      "--- Fold 30 started at Tue Apr 23 14:26:56 2019\n",
      "TN = 2 FN = 6 FP = 16 TP = 26\n",
      "AUC =  0.6059027777777778 Loss = 0.7007944319024682 Acc = 0.56\n",
      "--- Fold 31 started at Tue Apr 23 14:26:56 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.6805555555555556 Loss = 0.7169306848477572 Acc = 0.68\n",
      "--- Fold 32 started at Tue Apr 23 14:26:56 2019\n",
      "TN = 3 FN = 2 FP = 15 TP = 30\n",
      "AUC =  0.7309027777777778 Loss = 0.6546632701158523 Acc = 0.66\n",
      "--- Fold 33 started at Tue Apr 23 14:26:56 2019\n",
      "TN = 6 FN = 8 FP = 12 TP = 24\n",
      "AUC =  0.6145833333333334 Loss = 0.745200722925365 Acc = 0.6\n",
      "--- Fold 34 started at Tue Apr 23 14:26:56 2019\n",
      "TN = 12 FN = 5 FP = 6 TP = 27\n",
      "AUC =  0.8871527777777778 Loss = 0.41130477204918864 Acc = 0.78\n",
      "--- Fold 35 started at Tue Apr 23 14:26:57 2019\n",
      "TN = 10 FN = 5 FP = 8 TP = 27\n",
      "AUC =  0.734375 Loss = 0.6162723624613136 Acc = 0.74\n",
      "--- Fold 36 started at Tue Apr 23 14:26:57 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.8246527777777778 Loss = 0.5006120498478412 Acc = 0.74\n",
      "--- Fold 37 started at Tue Apr 23 14:26:57 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.6649305555555556 Loss = 0.7204831014573574 Acc = 0.64\n",
      "--- Fold 38 started at Tue Apr 23 14:26:57 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.6961805555555556 Loss = 0.6622264456376433 Acc = 0.74\n",
      "--- Fold 39 started at Tue Apr 23 14:26:57 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.6979166666666666 Loss = 0.6916278861835599 Acc = 0.66\n",
      "--- Fold 40 started at Tue Apr 23 14:26:57 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.6180555555555556 Loss = 0.7384640274755657 Acc = 0.64\n",
      "--- Fold 41 started at Tue Apr 23 14:26:57 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.7690972222222222 Loss = 0.5434190789796411 Acc = 0.7\n",
      "--- Fold 42 started at Tue Apr 23 14:26:58 2019\n",
      "TN = 8 FN = 7 FP = 10 TP = 25\n",
      "AUC =  0.6597222222222222 Loss = 0.7593090762291104 Acc = 0.66\n",
      "--- Fold 43 started at Tue Apr 23 14:26:58 2019\n",
      "TN = 7 FN = 1 FP = 11 TP = 31\n",
      "AUC =  0.763888888888889 Loss = 0.5809771287254989 Acc = 0.76\n",
      "--- Fold 44 started at Tue Apr 23 14:26:58 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.8385416666666666 Loss = 0.5164619778655469 Acc = 0.66\n",
      "--- Fold 45 started at Tue Apr 23 14:26:58 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.6770833333333333 Loss = 0.6696073954738676 Acc = 0.66\n",
      "--- Fold 46 started at Tue Apr 23 14:26:58 2019\n",
      "TN = 4 FN = 6 FP = 14 TP = 26\n",
      "AUC =  0.5642361111111112 Loss = 0.8007627673447132 Acc = 0.6\n",
      "--- Fold 47 started at Tue Apr 23 14:26:58 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.7847222222222222 Loss = 0.5420315215736627 Acc = 0.7\n",
      "--- Fold 48 started at Tue Apr 23 14:26:59 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.798611111111111 Loss = 0.5137648075725884 Acc = 0.68\n",
      "--- Fold 49 started at Tue Apr 23 14:26:59 2019\n",
      "TN = 6 FN = 7 FP = 12 TP = 25\n",
      "AUC =  0.6059027777777778 Loss = 0.8190134687069803 Acc = 0.62\n",
      "--- Fold 50 started at Tue Apr 23 14:26:59 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.6215277777777778 Loss = 0.7545853465422988 Acc = 0.66\n",
      "--- Fold 51 started at Tue Apr 23 14:26:59 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.625 Loss = 0.7073119255341589 Acc = 0.64\n",
      "--- Fold 52 started at Tue Apr 23 14:26:59 2019\n",
      "TN = 8 FN = 9 FP = 10 TP = 23\n",
      "AUC =  0.5451388888888888 Loss = 0.8007803679257631 Acc = 0.62\n",
      "--- Fold 53 started at Tue Apr 23 14:26:59 2019\n",
      "TN = 9 FN = 1 FP = 9 TP = 31\n",
      "AUC =  0.8732638888888888 Loss = 0.5011372599657625 Acc = 0.8\n",
      "--- Fold 54 started at Tue Apr 23 14:27:00 2019\n",
      "TN = 8 FN = 1 FP = 10 TP = 31\n",
      "AUC =  0.8246527777777778 Loss = 0.4920602543652058 Acc = 0.78\n",
      "--- Fold 55 started at Tue Apr 23 14:27:00 2019\n",
      "TN = 7 FN = 2 FP = 11 TP = 30\n",
      "AUC =  0.6892361111111112 Loss = 0.6574041966721416 Acc = 0.74\n",
      "--- Fold 56 started at Tue Apr 23 14:27:00 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.7482638888888888 Loss = 0.5844481410458684 Acc = 0.68\n",
      "--- Fold 57 started at Tue Apr 23 14:27:00 2019\n",
      "TN = 6 FN = 8 FP = 12 TP = 24\n",
      "AUC =  0.5520833333333333 Loss = 0.8714351418800652 Acc = 0.6\n",
      "--- Fold 58 started at Tue Apr 23 14:27:00 2019\n",
      "TN = 6 FN = 2 FP = 12 TP = 30\n",
      "AUC =  0.736111111111111 Loss = 0.5761242963373661 Acc = 0.72\n",
      "--- Fold 59 started at Tue Apr 23 14:27:00 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.7447916666666667 Loss = 0.5665148663986475 Acc = 0.68\n",
      "--- Fold 60 started at Tue Apr 23 14:27:01 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.7621527777777778 Loss = 0.5670658625662327 Acc = 0.7\n",
      "--- Fold 61 started at Tue Apr 23 14:27:01 2019\n",
      "TN = 4 FN = 6 FP = 14 TP = 26\n",
      "AUC =  0.638888888888889 Loss = 0.7182202291861176 Acc = 0.6\n",
      "--- Fold 62 started at Tue Apr 23 14:27:01 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.7222222222222222 Loss = 0.6500205474812537 Acc = 0.68\n",
      "--- Fold 63 started at Tue Apr 23 14:27:01 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.7204861111111112 Loss = 0.6051143745705485 Acc = 0.68\n",
      "--- Fold 64 started at Tue Apr 23 14:27:02 2019\n",
      "TN = 7 FN = 1 FP = 11 TP = 31\n",
      "AUC =  0.7013888888888888 Loss = 0.6313418358936906 Acc = 0.76\n",
      "--- Fold 65 started at Tue Apr 23 14:27:02 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.8107638888888888 Loss = 0.5574904861301184 Acc = 0.68\n",
      "--- Fold 66 started at Tue Apr 23 14:27:02 2019\n",
      "TN = 5 FN = 6 FP = 13 TP = 26\n",
      "AUC =  0.6510416666666666 Loss = 0.7740861612185835 Acc = 0.62\n",
      "--- Fold 67 started at Tue Apr 23 14:27:02 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.6788194444444444 Loss = 0.6340355860814452 Acc = 0.7\n",
      "--- Fold 68 started at Tue Apr 23 14:27:02 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.7847222222222223 Loss = 0.5981202541850508 Acc = 0.74\n",
      "--- Fold 69 started at Tue Apr 23 14:27:03 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7413194444444445 Loss = 0.5892198868468403 Acc = 0.72\n",
      "--- Fold 70 started at Tue Apr 23 14:27:03 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.6631944444444445 Loss = 0.6920141445845366 Acc = 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 71 started at Tue Apr 23 14:27:03 2019\n",
      "TN = 8 FN = 2 FP = 10 TP = 30\n",
      "AUC =  0.8385416666666666 Loss = 0.4935785057581961 Acc = 0.76\n",
      "--- Fold 72 started at Tue Apr 23 14:27:03 2019\n",
      "TN = 9 FN = 3 FP = 9 TP = 29\n",
      "AUC =  0.7881944444444444 Loss = 0.5403956609033048 Acc = 0.76\n",
      "--- Fold 73 started at Tue Apr 23 14:27:03 2019\n",
      "TN = 6 FN = 8 FP = 12 TP = 24\n",
      "AUC =  0.6302083333333334 Loss = 0.7409862062707543 Acc = 0.6\n",
      "--- Fold 74 started at Tue Apr 23 14:27:04 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.5902777777777778 Loss = 0.8471939123049378 Acc = 0.64\n",
      "--- Fold 75 started at Tue Apr 23 14:27:04 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.7378472222222222 Loss = 0.6105434928275645 Acc = 0.66\n",
      "--- Fold 76 started at Tue Apr 23 14:27:04 2019\n",
      "TN = 10 FN = 2 FP = 8 TP = 30\n",
      "AUC =  0.8402777777777778 Loss = 0.4813984830863774 Acc = 0.8\n",
      "--- Fold 77 started at Tue Apr 23 14:27:04 2019\n",
      "TN = 5 FN = 2 FP = 13 TP = 30\n",
      "AUC =  0.6736111111111112 Loss = 0.635188992023468 Acc = 0.7\n",
      "--- Fold 78 started at Tue Apr 23 14:27:04 2019\n",
      "TN = 7 FN = 7 FP = 11 TP = 25\n",
      "AUC =  0.6701388888888888 Loss = 0.6885411349684 Acc = 0.64\n",
      "--- Fold 79 started at Tue Apr 23 14:27:05 2019\n",
      "TN = 8 FN = 4 FP = 10 TP = 28\n",
      "AUC =  0.7256944444444444 Loss = 0.5954732822068035 Acc = 0.72\n",
      "--- Fold 80 started at Tue Apr 23 14:27:05 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.732638888888889 Loss = 0.6090872472524643 Acc = 0.72\n",
      "--- Fold 81 started at Tue Apr 23 14:27:05 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.6736111111111112 Loss = 0.6963455842062831 Acc = 0.7\n",
      "--- Fold 82 started at Tue Apr 23 14:27:05 2019\n",
      "TN = 9 FN = 0 FP = 9 TP = 32\n",
      "AUC =  0.7621527777777778 Loss = 0.5739185045659542 Acc = 0.82\n",
      "--- Fold 83 started at Tue Apr 23 14:27:05 2019\n",
      "TN = 11 FN = 4 FP = 7 TP = 28\n",
      "AUC =  0.7083333333333333 Loss = 0.6567861492186785 Acc = 0.78\n",
      "--- Fold 84 started at Tue Apr 23 14:27:06 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.8125 Loss = 0.5488573838211596 Acc = 0.72\n",
      "--- Fold 85 started at Tue Apr 23 14:27:06 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.6475694444444444 Loss = 0.7526942909695208 Acc = 0.64\n",
      "--- Fold 86 started at Tue Apr 23 14:27:06 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.7604166666666666 Loss = 0.5695784722268581 Acc = 0.74\n",
      "--- Fold 87 started at Tue Apr 23 14:27:06 2019\n",
      "TN = 7 FN = 8 FP = 11 TP = 24\n",
      "AUC =  0.7204861111111113 Loss = 0.5881516559049487 Acc = 0.62\n",
      "--- Fold 88 started at Tue Apr 23 14:27:06 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.7274305555555556 Loss = 0.6099133124575019 Acc = 0.68\n",
      "--- Fold 89 started at Tue Apr 23 14:27:07 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.7413194444444444 Loss = 0.5975745626911521 Acc = 0.74\n",
      "--- Fold 90 started at Tue Apr 23 14:27:07 2019\n",
      "TN = 8 FN = 7 FP = 10 TP = 25\n",
      "AUC =  0.78125 Loss = 0.5467321518622339 Acc = 0.66\n",
      "--- Fold 91 started at Tue Apr 23 14:27:07 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.6371527777777778 Loss = 0.6991945481486619 Acc = 0.68\n",
      "--- Fold 92 started at Tue Apr 23 14:27:07 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.717013888888889 Loss = 0.6848694082163275 Acc = 0.68\n",
      "--- Fold 93 started at Tue Apr 23 14:27:07 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.7239583333333334 Loss = 0.5849324355646968 Acc = 0.66\n",
      "--- Fold 94 started at Tue Apr 23 14:27:08 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.638888888888889 Loss = 0.7895874631963671 Acc = 0.7\n",
      "--- Fold 95 started at Tue Apr 23 14:27:08 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.6493055555555555 Loss = 0.6767323938943446 Acc = 0.72\n",
      "--- Fold 96 started at Tue Apr 23 14:27:08 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.7118055555555556 Loss = 0.6399501374736428 Acc = 0.72\n",
      "--- Fold 97 started at Tue Apr 23 14:27:08 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.717013888888889 Loss = 0.6620057152677328 Acc = 0.68\n",
      "--- Fold 98 started at Tue Apr 23 14:27:09 2019\n",
      "TN = 8 FN = 4 FP = 10 TP = 28\n",
      "AUC =  0.7378472222222223 Loss = 0.6261368880048395 Acc = 0.72\n",
      "--- Fold 99 started at Tue Apr 23 14:27:09 2019\n",
      "TN = 9 FN = 3 FP = 9 TP = 29\n",
      "AUC =  0.7934027777777778 Loss = 0.5272391496598721 Acc = 0.76\n",
      "model model_xgb: 0      0.779973\n",
      "1      0.657229\n",
      "2      0.938668\n",
      "3      0.715920\n",
      "4      0.862532\n",
      "5      0.906241\n",
      "6      0.504915\n",
      "7      0.863873\n",
      "8      0.726049\n",
      "9      0.696863\n",
      "10     0.518395\n",
      "11     0.775166\n",
      "12     0.834251\n",
      "13     0.392978\n",
      "14     0.681512\n",
      "15     0.977732\n",
      "16     0.964158\n",
      "17     0.785208\n",
      "18     0.978635\n",
      "19     0.772260\n",
      "20     0.910954\n",
      "21     0.886845\n",
      "22     0.229886\n",
      "23     0.265256\n",
      "24     0.458538\n",
      "25     0.744313\n",
      "26     0.863083\n",
      "27     0.863256\n",
      "28     0.887488\n",
      "29     0.709281\n",
      "         ...   \n",
      "220    0.859489\n",
      "221    0.854814\n",
      "222    0.901981\n",
      "223    0.619897\n",
      "224    0.835146\n",
      "225    0.540120\n",
      "226    0.948277\n",
      "227    0.261676\n",
      "228    0.942519\n",
      "229    0.937391\n",
      "230    0.664153\n",
      "231    0.949973\n",
      "232    0.944429\n",
      "233    0.618392\n",
      "234    0.509418\n",
      "235    0.681305\n",
      "236    0.820662\n",
      "237    0.786540\n",
      "238    0.806079\n",
      "239    0.667915\n",
      "240    0.300929\n",
      "241    0.583225\n",
      "242    0.762119\n",
      "243    0.898858\n",
      "244    0.732758\n",
      "245    0.585876\n",
      "246    0.606269\n",
      "247    0.902929\n",
      "248    0.606545\n",
      "249    0.281418\n",
      "Length: 250, dtype: float32\n",
      "--- Fold 0 started at Tue Apr 23 14:27:09 2019\n",
      "TN = 11 FN = 5 FP = 7 TP = 27\n",
      "AUC =  0.8159722222222222 Loss = 0.4980619794248275 Acc = 0.76\n",
      "--- Fold 1 started at Tue Apr 23 14:27:09 2019\n",
      "TN = 14 FN = 11 FP = 4 TP = 21\n",
      "AUC =  0.8055555555555556 Loss = 0.5713760645009691 Acc = 0.7\n",
      "--- Fold 2 started at Tue Apr 23 14:27:10 2019\n",
      "TN = 12 FN = 7 FP = 6 TP = 25\n",
      "AUC =  0.8194444444444444 Loss = 0.495624205347428 Acc = 0.74\n",
      "--- Fold 3 started at Tue Apr 23 14:27:10 2019\n",
      "TN = 8 FN = 8 FP = 10 TP = 24\n",
      "AUC =  0.7378472222222222 Loss = 0.5676065425364962 Acc = 0.64\n",
      "--- Fold 4 started at Tue Apr 23 14:27:10 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.795138888888889 Loss = 0.5242581850346698 Acc = 0.7\n",
      "--- Fold 5 started at Tue Apr 23 14:27:10 2019\n",
      "TN = 11 FN = 8 FP = 7 TP = 24\n",
      "AUC =  0.8020833333333334 Loss = 0.5333891163907283 Acc = 0.7\n",
      "--- Fold 6 started at Tue Apr 23 14:27:10 2019\n",
      "TN = 11 FN = 7 FP = 7 TP = 25\n",
      "AUC =  0.7239583333333334 Loss = 0.6208325343232672 Acc = 0.72\n",
      "--- Fold 7 started at Tue Apr 23 14:27:11 2019\n",
      "TN = 8 FN = 8 FP = 10 TP = 24\n",
      "AUC =  0.6927083333333333 Loss = 0.5842970346934354 Acc = 0.64\n",
      "--- Fold 8 started at Tue Apr 23 14:27:11 2019\n",
      "TN = 11 FN = 10 FP = 7 TP = 22\n",
      "AUC =  0.7690972222222223 Loss = 0.5298611461413415 Acc = 0.66\n",
      "--- Fold 9 started at Tue Apr 23 14:27:11 2019\n",
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.7604166666666666 Loss = 0.5503365698292678 Acc = 0.68\n",
      "--- Fold 10 started at Tue Apr 23 14:27:11 2019\n",
      "TN = 10 FN = 7 FP = 8 TP = 25\n",
      "AUC =  0.78125 Loss = 0.5538314127334629 Acc = 0.7\n",
      "--- Fold 11 started at Tue Apr 23 14:27:12 2019\n",
      "TN = 9 FN = 8 FP = 9 TP = 24\n",
      "AUC =  0.6909722222222222 Loss = 0.5952348377939507 Acc = 0.66\n",
      "--- Fold 12 started at Tue Apr 23 14:27:12 2019\n",
      "TN = 15 FN = 7 FP = 3 TP = 25\n",
      "AUC =  0.8142361111111112 Loss = 0.5145406263505149 Acc = 0.8\n",
      "--- Fold 13 started at Tue Apr 23 14:27:12 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7309027777777777 Loss = 0.6030723842975998 Acc = 0.72\n",
      "--- Fold 14 started at Tue Apr 23 14:27:13 2019\n",
      "TN = 12 FN = 9 FP = 6 TP = 23\n",
      "AUC =  0.8350694444444445 Loss = 0.49246577562727917 Acc = 0.7\n",
      "--- Fold 15 started at Tue Apr 23 14:27:13 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.7621527777777778 Loss = 0.560006039854994 Acc = 0.72\n",
      "--- Fold 16 started at Tue Apr 23 14:27:13 2019\n",
      "TN = 14 FN = 4 FP = 4 TP = 28\n",
      "AUC =  0.8680555555555556 Loss = 0.4581593219702858 Acc = 0.84\n",
      "--- Fold 17 started at Tue Apr 23 14:27:13 2019\n",
      "TN = 13 FN = 5 FP = 5 TP = 27\n",
      "AUC =  0.8420138888888888 Loss = 0.45836991743882904 Acc = 0.8\n",
      "--- Fold 18 started at Tue Apr 23 14:27:14 2019\n",
      "TN = 15 FN = 9 FP = 3 TP = 23\n",
      "AUC =  0.8559027777777777 Loss = 0.5171088447940668 Acc = 0.76\n",
      "--- Fold 19 started at Tue Apr 23 14:27:14 2019\n",
      "TN = 11 FN = 6 FP = 7 TP = 26\n",
      "AUC =  0.7934027777777778 Loss = 0.5399980760446168 Acc = 0.74\n",
      "--- Fold 20 started at Tue Apr 23 14:27:14 2019\n",
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.8003472222222222 Loss = 0.5147414025961788 Acc = 0.68\n",
      "--- Fold 21 started at Tue Apr 23 14:27:15 2019\n",
      "TN = 9 FN = 7 FP = 9 TP = 25\n",
      "AUC =  0.7934027777777778 Loss = 0.5235411107332627 Acc = 0.68\n",
      "--- Fold 22 started at Tue Apr 23 14:27:15 2019\n",
      "TN = 12 FN = 7 FP = 6 TP = 25\n",
      "AUC =  0.8107638888888888 Loss = 0.5138904182432743 Acc = 0.74\n",
      "--- Fold 23 started at Tue Apr 23 14:27:16 2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.7725694444444444 Loss = 0.5215289414948762 Acc = 0.68\n",
      "--- Fold 24 started at Tue Apr 23 14:27:16 2019\n",
      "TN = 14 FN = 11 FP = 4 TP = 21\n",
      "AUC =  0.7586805555555556 Loss = 0.6191301102801997 Acc = 0.7\n",
      "--- Fold 25 started at Tue Apr 23 14:27:16 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.8159722222222221 Loss = 0.5166820977068908 Acc = 0.72\n",
      "--- Fold 26 started at Tue Apr 23 14:27:17 2019\n",
      "TN = 12 FN = 7 FP = 6 TP = 25\n",
      "AUC =  0.8055555555555555 Loss = 0.5380120839027193 Acc = 0.74\n",
      "--- Fold 27 started at Tue Apr 23 14:27:17 2019\n",
      "TN = 14 FN = 8 FP = 4 TP = 24\n",
      "AUC =  0.8315972222222222 Loss = 0.4996474086510836 Acc = 0.76\n",
      "--- Fold 28 started at Tue Apr 23 14:27:17 2019\n",
      "TN = 12 FN = 3 FP = 6 TP = 29\n",
      "AUC =  0.8749999999999999 Loss = 0.4242136457089521 Acc = 0.82\n",
      "--- Fold 29 started at Tue Apr 23 14:27:18 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.7795138888888888 Loss = 0.5671167352862044 Acc = 0.68\n",
      "--- Fold 30 started at Tue Apr 23 14:27:18 2019\n",
      "TN = 12 FN = 8 FP = 6 TP = 24\n",
      "AUC =  0.7760416666666667 Loss = 0.5752206822231797 Acc = 0.72\n",
      "--- Fold 31 started at Tue Apr 23 14:27:18 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.7222222222222222 Loss = 0.5830049885535091 Acc = 0.7\n",
      "--- Fold 32 started at Tue Apr 23 14:27:19 2019\n",
      "TN = 12 FN = 5 FP = 6 TP = 27\n",
      "AUC =  0.8333333333333334 Loss = 0.486171985766126 Acc = 0.78\n",
      "--- Fold 33 started at Tue Apr 23 14:27:19 2019\n",
      "TN = 14 FN = 8 FP = 4 TP = 24\n",
      "AUC =  0.845486111111111 Loss = 0.4936525707035959 Acc = 0.76\n",
      "--- Fold 34 started at Tue Apr 23 14:27:19 2019\n",
      "TN = 13 FN = 7 FP = 5 TP = 25\n",
      "AUC =  0.875 Loss = 0.4334440524276363 Acc = 0.76\n",
      "--- Fold 35 started at Tue Apr 23 14:27:19 2019\n",
      "TN = 14 FN = 5 FP = 4 TP = 27\n",
      "AUC =  0.8906249999999999 Loss = 0.4338774867747166 Acc = 0.82\n",
      "--- Fold 36 started at Tue Apr 23 14:27:20 2019\n",
      "TN = 15 FN = 10 FP = 3 TP = 22\n",
      "AUC =  0.8697916666666666 Loss = 0.46065095433511816 Acc = 0.74\n",
      "--- Fold 37 started at Tue Apr 23 14:27:20 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.7743055555555556 Loss = 0.5416876896890224 Acc = 0.7\n",
      "--- Fold 38 started at Tue Apr 23 14:27:20 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.7465277777777777 Loss = 0.573510466251875 Acc = 0.74\n",
      "--- Fold 39 started at Tue Apr 23 14:27:20 2019\n",
      "TN = 10 FN = 10 FP = 8 TP = 22\n",
      "AUC =  0.7465277777777778 Loss = 0.5737766245567689 Acc = 0.64\n",
      "--- Fold 40 started at Tue Apr 23 14:27:20 2019\n",
      "TN = 11 FN = 7 FP = 7 TP = 25\n",
      "AUC =  0.798611111111111 Loss = 0.5169312978547375 Acc = 0.72\n",
      "--- Fold 41 started at Tue Apr 23 14:27:21 2019\n",
      "TN = 11 FN = 10 FP = 7 TP = 22\n",
      "AUC =  0.7013888888888888 Loss = 0.6799665242013817 Acc = 0.66\n",
      "--- Fold 42 started at Tue Apr 23 14:27:21 2019\n",
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.7482638888888888 Loss = 0.5896443450033382 Acc = 0.68\n",
      "--- Fold 43 started at Tue Apr 23 14:27:21 2019\n",
      "TN = 9 FN = 8 FP = 9 TP = 24\n",
      "AUC =  0.7239583333333334 Loss = 0.5827904240730554 Acc = 0.66\n",
      "--- Fold 44 started at Tue Apr 23 14:27:21 2019\n",
      "TN = 15 FN = 8 FP = 3 TP = 24\n",
      "AUC =  0.84375 Loss = 0.4719583536044787 Acc = 0.78\n",
      "--- Fold 45 started at Tue Apr 23 14:27:22 2019\n",
      "TN = 11 FN = 8 FP = 7 TP = 24\n",
      "AUC =  0.7465277777777778 Loss = 0.5583336005112689 Acc = 0.7\n",
      "--- Fold 46 started at Tue Apr 23 14:27:22 2019\n",
      "TN = 11 FN = 6 FP = 7 TP = 26\n",
      "AUC =  0.7152777777777779 Loss = 0.6504520017336272 Acc = 0.74\n",
      "--- Fold 47 started at Tue Apr 23 14:27:22 2019\n",
      "TN = 11 FN = 8 FP = 7 TP = 24\n",
      "AUC =  0.7916666666666667 Loss = 0.5257267921545211 Acc = 0.7\n",
      "--- Fold 48 started at Tue Apr 23 14:27:22 2019\n",
      "TN = 13 FN = 6 FP = 5 TP = 26\n",
      "AUC =  0.875 Loss = 0.4587697847992771 Acc = 0.78\n",
      "--- Fold 49 started at Tue Apr 23 14:27:22 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.6822916666666666 Loss = 0.623314374877741 Acc = 0.7\n",
      "--- Fold 50 started at Tue Apr 23 14:27:23 2019\n",
      "TN = 10 FN = 8 FP = 8 TP = 24\n",
      "AUC =  0.7777777777777778 Loss = 0.6032785216294334 Acc = 0.68\n",
      "--- Fold 51 started at Tue Apr 23 14:27:23 2019\n",
      "TN = 9 FN = 11 FP = 9 TP = 21\n",
      "AUC =  0.6336805555555555 Loss = 0.741151636539652 Acc = 0.6\n",
      "--- Fold 52 started at Tue Apr 23 14:27:23 2019\n",
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.7708333333333334 Loss = 0.5552609106357606 Acc = 0.68\n",
      "--- Fold 53 started at Tue Apr 23 14:27:23 2019\n",
      "TN = 11 FN = 4 FP = 7 TP = 28\n",
      "AUC =  0.8506944444444444 Loss = 0.4705144942666455 Acc = 0.78\n",
      "--- Fold 54 started at Tue Apr 23 14:27:24 2019\n",
      "TN = 13 FN = 2 FP = 5 TP = 30\n",
      "AUC =  0.876736111111111 Loss = 0.4325257859430607 Acc = 0.86\n",
      "--- Fold 55 started at Tue Apr 23 14:27:24 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.7256944444444445 Loss = 0.5874679997381914 Acc = 0.66\n",
      "--- Fold 56 started at Tue Apr 23 14:27:24 2019\n",
      "TN = 11 FN = 3 FP = 7 TP = 29\n",
      "AUC =  0.8663194444444444 Loss = 0.41428167239524094 Acc = 0.8\n",
      "--- Fold 57 started at Tue Apr 23 14:27:24 2019\n",
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.7291666666666666 Loss = 0.5996362828344044 Acc = 0.68\n",
      "--- Fold 58 started at Tue Apr 23 14:27:25 2019\n",
      "TN = 11 FN = 8 FP = 7 TP = 24\n",
      "AUC =  0.765625 Loss = 0.5607887763346575 Acc = 0.7\n",
      "--- Fold 59 started at Tue Apr 23 14:27:25 2019\n",
      "TN = 13 FN = 13 FP = 5 TP = 19\n",
      "AUC =  0.7361111111111112 Loss = 0.6065663534621695 Acc = 0.64\n",
      "--- Fold 60 started at Tue Apr 23 14:27:25 2019\n",
      "TN = 10 FN = 7 FP = 8 TP = 25\n",
      "AUC =  0.765625 Loss = 0.5570779176588304 Acc = 0.7\n",
      "--- Fold 61 started at Tue Apr 23 14:27:25 2019\n",
      "TN = 12 FN = 9 FP = 6 TP = 23\n",
      "AUC =  0.7621527777777778 Loss = 0.55258842222548 Acc = 0.7\n",
      "--- Fold 62 started at Tue Apr 23 14:27:25 2019\n",
      "TN = 13 FN = 7 FP = 5 TP = 25\n",
      "AUC =  0.8385416666666667 Loss = 0.4619088794151016 Acc = 0.76\n",
      "--- Fold 63 started at Tue Apr 23 14:27:26 2019\n",
      "TN = 10 FN = 4 FP = 8 TP = 28\n",
      "AUC =  0.7881944444444444 Loss = 0.5453897306998401 Acc = 0.76\n",
      "--- Fold 64 started at Tue Apr 23 14:27:26 2019\n",
      "TN = 14 FN = 9 FP = 4 TP = 23\n",
      "AUC =  0.7690972222222222 Loss = 0.6146728019210072 Acc = 0.74\n",
      "--- Fold 65 started at Tue Apr 23 14:27:26 2019\n",
      "TN = 12 FN = 7 FP = 6 TP = 25\n",
      "AUC =  0.8020833333333334 Loss = 0.5088532712736833 Acc = 0.74\n",
      "--- Fold 66 started at Tue Apr 23 14:27:26 2019\n",
      "TN = 11 FN = 8 FP = 7 TP = 24\n",
      "AUC =  0.7152777777777778 Loss = 0.6331421187751767 Acc = 0.7\n",
      "--- Fold 67 started at Tue Apr 23 14:27:27 2019\n",
      "TN = 11 FN = 7 FP = 7 TP = 25\n",
      "AUC =  0.78125 Loss = 0.5355425550062003 Acc = 0.72\n",
      "--- Fold 68 started at Tue Apr 23 14:27:27 2019\n",
      "TN = 11 FN = 7 FP = 7 TP = 25\n",
      "AUC =  0.7934027777777777 Loss = 0.5659811975128936 Acc = 0.72\n",
      "--- Fold 69 started at Tue Apr 23 14:27:27 2019\n",
      "TN = 12 FN = 11 FP = 6 TP = 21\n",
      "AUC =  0.748263888888889 Loss = 0.5903697421469635 Acc = 0.66\n",
      "--- Fold 70 started at Tue Apr 23 14:27:27 2019\n",
      "TN = 13 FN = 8 FP = 5 TP = 24\n",
      "AUC =  0.7621527777777777 Loss = 0.5628598903898435 Acc = 0.74\n",
      "--- Fold 71 started at Tue Apr 23 14:27:27 2019\n",
      "TN = 14 FN = 7 FP = 4 TP = 25\n",
      "AUC =  0.857638888888889 Loss = 0.4581621850465848 Acc = 0.78\n",
      "--- Fold 72 started at Tue Apr 23 14:27:28 2019\n",
      "TN = 12 FN = 7 FP = 6 TP = 25\n",
      "AUC =  0.7916666666666666 Loss = 0.5652861694232739 Acc = 0.74\n",
      "--- Fold 73 started at Tue Apr 23 14:27:28 2019\n",
      "TN = 14 FN = 8 FP = 4 TP = 24\n",
      "AUC =  0.8194444444444444 Loss = 0.5226967183356575 Acc = 0.76\n",
      "--- Fold 74 started at Tue Apr 23 14:27:28 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.7291666666666666 Loss = 0.5828232867885018 Acc = 0.7\n",
      "--- Fold 75 started at Tue Apr 23 14:27:28 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.828125 Loss = 0.4653146671955601 Acc = 0.72\n",
      "--- Fold 76 started at Tue Apr 23 14:27:29 2019\n",
      "TN = 13 FN = 10 FP = 5 TP = 22\n",
      "AUC =  0.8107638888888888 Loss = 0.5019623407057918 Acc = 0.7\n",
      "--- Fold 77 started at Tue Apr 23 14:27:29 2019\n",
      "TN = 10 FN = 5 FP = 8 TP = 27\n",
      "AUC =  0.8559027777777778 Loss = 0.4367898594413482 Acc = 0.74\n",
      "--- Fold 78 started at Tue Apr 23 14:27:29 2019\n",
      "TN = 15 FN = 11 FP = 3 TP = 21\n",
      "AUC =  0.7864583333333334 Loss = 0.5895149480501387 Acc = 0.72\n",
      "--- Fold 79 started at Tue Apr 23 14:27:29 2019\n",
      "TN = 12 FN = 8 FP = 6 TP = 24\n",
      "AUC =  0.7604166666666667 Loss = 0.5675148356423786 Acc = 0.72\n",
      "--- Fold 80 started at Tue Apr 23 14:27:30 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.7760416666666666 Loss = 0.5466849069703495 Acc = 0.7\n",
      "--- Fold 81 started at Tue Apr 23 14:27:30 2019\n",
      "TN = 10 FN = 9 FP = 8 TP = 23\n",
      "AUC =  0.71875 Loss = 0.5985898528637079 Acc = 0.66\n",
      "--- Fold 82 started at Tue Apr 23 14:27:30 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7378472222222222 Loss = 0.558651267356861 Acc = 0.72\n",
      "--- Fold 83 started at Tue Apr 23 14:27:30 2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN = 13 FN = 8 FP = 5 TP = 24\n",
      "AUC =  0.7899305555555555 Loss = 0.5753991790591931 Acc = 0.74\n",
      "--- Fold 84 started at Tue Apr 23 14:27:30 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7829861111111112 Loss = 0.5417387696205469 Acc = 0.72\n",
      "--- Fold 85 started at Tue Apr 23 14:27:31 2019\n",
      "TN = 13 FN = 11 FP = 5 TP = 21\n",
      "AUC =  0.7326388888888888 Loss = 0.6408593658164446 Acc = 0.68\n",
      "--- Fold 86 started at Tue Apr 23 14:27:31 2019\n",
      "TN = 10 FN = 7 FP = 8 TP = 25\n",
      "AUC =  0.7743055555555556 Loss = 0.5450354423993423 Acc = 0.7\n",
      "--- Fold 87 started at Tue Apr 23 14:27:31 2019\n",
      "TN = 12 FN = 7 FP = 6 TP = 25\n",
      "AUC =  0.7951388888888888 Loss = 0.5120303307708496 Acc = 0.74\n",
      "--- Fold 88 started at Tue Apr 23 14:27:31 2019\n",
      "TN = 11 FN = 7 FP = 7 TP = 25\n",
      "AUC =  0.7708333333333334 Loss = 0.5277270409252568 Acc = 0.72\n",
      "--- Fold 89 started at Tue Apr 23 14:27:32 2019\n",
      "TN = 12 FN = 6 FP = 6 TP = 26\n",
      "AUC =  0.7881944444444444 Loss = 0.5358456234756808 Acc = 0.76\n",
      "--- Fold 90 started at Tue Apr 23 14:27:32 2019\n",
      "TN = 14 FN = 9 FP = 4 TP = 23\n",
      "AUC =  0.7951388888888888 Loss = 0.56944356519045 Acc = 0.74\n",
      "--- Fold 91 started at Tue Apr 23 14:27:32 2019\n",
      "TN = 11 FN = 7 FP = 7 TP = 25\n",
      "AUC =  0.6909722222222222 Loss = 0.6803030663090862 Acc = 0.72\n",
      "--- Fold 92 started at Tue Apr 23 14:27:32 2019\n",
      "TN = 11 FN = 6 FP = 7 TP = 26\n",
      "AUC =  0.765625 Loss = 0.5346758519047914 Acc = 0.74\n",
      "--- Fold 93 started at Tue Apr 23 14:27:32 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.8038194444444445 Loss = 0.52301430219408 Acc = 0.72\n",
      "--- Fold 94 started at Tue Apr 23 14:27:33 2019\n",
      "TN = 9 FN = 3 FP = 9 TP = 29\n",
      "AUC =  0.8385416666666667 Loss = 0.46004058498278594 Acc = 0.76\n",
      "--- Fold 95 started at Tue Apr 23 14:27:33 2019\n",
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.7447916666666667 Loss = 0.5869060951551048 Acc = 0.68\n",
      "--- Fold 96 started at Tue Apr 23 14:27:33 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.7222222222222222 Loss = 0.5896086513429311 Acc = 0.72\n",
      "--- Fold 97 started at Tue Apr 23 14:27:33 2019\n",
      "TN = 13 FN = 4 FP = 5 TP = 28\n",
      "AUC =  0.8715277777777778 Loss = 0.4461355879905212 Acc = 0.82\n",
      "--- Fold 98 started at Tue Apr 23 14:27:33 2019\n",
      "TN = 12 FN = 3 FP = 6 TP = 29\n",
      "AUC =  0.8628472222222223 Loss = 0.4628994085707167 Acc = 0.82\n",
      "--- Fold 99 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 11 FN = 4 FP = 7 TP = 28\n",
      "AUC =  0.8333333333333333 Loss = 0.4562792795406566 Acc = 0.78\n",
      "model model_lr: 0      0.809531\n",
      "1      0.328080\n",
      "2      0.844999\n",
      "3      0.572648\n",
      "4      0.736097\n",
      "5      0.866211\n",
      "6      0.709340\n",
      "7      0.722418\n",
      "8      0.588842\n",
      "9      0.690776\n",
      "10     0.404235\n",
      "11     0.640246\n",
      "12     0.805794\n",
      "13     0.060315\n",
      "14     0.638119\n",
      "15     0.941028\n",
      "16     0.883424\n",
      "17     0.548295\n",
      "18     0.892559\n",
      "19     0.702442\n",
      "20     0.701813\n",
      "21     0.627928\n",
      "22     0.044442\n",
      "23     0.154264\n",
      "24     0.251044\n",
      "25     0.469153\n",
      "26     0.628536\n",
      "27     0.894764\n",
      "28     0.910081\n",
      "29     0.544509\n",
      "         ...   \n",
      "220    0.821843\n",
      "221    0.770439\n",
      "222    0.732267\n",
      "223    0.686130\n",
      "224    0.831795\n",
      "225    0.538206\n",
      "226    0.983718\n",
      "227    0.164474\n",
      "228    0.652373\n",
      "229    0.886528\n",
      "230    0.680204\n",
      "231    0.963217\n",
      "232    0.817627\n",
      "233    0.533305\n",
      "234    0.174714\n",
      "235    0.712321\n",
      "236    0.904903\n",
      "237    0.877802\n",
      "238    0.602603\n",
      "239    0.489356\n",
      "240    0.371686\n",
      "241    0.409260\n",
      "242    0.525123\n",
      "243    0.693202\n",
      "244    0.476195\n",
      "245    0.683978\n",
      "246    0.284032\n",
      "247    0.570425\n",
      "248    0.724697\n",
      "249    0.179109\n",
      "Length: 250, dtype: float64\n",
      "--- Fold 0 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 10 FN = 1 FP = 8 TP = 31\n",
      "AUC =  0.8159722222222222 Loss = 0.7789443597247023 Acc = 0.82\n",
      "--- Fold 1 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 10 FN = 8 FP = 8 TP = 24\n",
      "AUC =  0.7413194444444444 Loss = 0.9244749313823725 Acc = 0.68\n",
      "--- Fold 2 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 9 FN = 8 FP = 9 TP = 24\n",
      "AUC =  0.7534722222222223 Loss = 0.9955650011168256 Acc = 0.66\n",
      "--- Fold 3 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 7 FN = 1 FP = 11 TP = 31\n",
      "AUC =  0.7673611111111112 Loss = 0.9400862118748015 Acc = 0.76\n",
      "--- Fold 4 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.7552083333333333 Loss = 0.9996449904681736 Acc = 0.7\n",
      "--- Fold 5 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.6684027777777777 Loss = 1.44911254720994 Acc = 0.64\n",
      "--- Fold 6 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.7152777777777779 Loss = 1.168266586707974 Acc = 0.74\n",
      "--- Fold 7 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.7777777777777777 Loss = 0.9121838512139097 Acc = 0.7\n",
      "--- Fold 8 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 11 FN = 9 FP = 7 TP = 23\n",
      "AUC =  0.7638888888888888 Loss = 0.896854697221826 Acc = 0.68\n",
      "--- Fold 9 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.7013888888888888 Loss = 1.2651296798293832 Acc = 0.66\n",
      "--- Fold 10 started at Tue Apr 23 14:27:34 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.7604166666666666 Loss = 0.9776001718811415 Acc = 0.74\n",
      "--- Fold 11 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.6909722222222222 Loss = 1.2721285854575555 Acc = 0.64\n",
      "--- Fold 12 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 12 FN = 3 FP = 6 TP = 29\n",
      "AUC =  0.8489583333333334 Loss = 0.6599244636120847 Acc = 0.82\n",
      "--- Fold 13 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 7 FN = 2 FP = 11 TP = 30\n",
      "AUC =  0.7361111111111112 Loss = 1.0247109313604765 Acc = 0.74\n",
      "--- Fold 14 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.7118055555555555 Loss = 1.1521058337217722 Acc = 0.74\n",
      "--- Fold 15 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.734375 Loss = 1.0626666488432985 Acc = 0.74\n",
      "--- Fold 16 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.6684027777777779 Loss = 1.1354927219066402 Acc = 0.66\n",
      "--- Fold 17 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.748263888888889 Loss = 1.1932990173449165 Acc = 0.7\n",
      "--- Fold 18 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 11 FN = 3 FP = 7 TP = 29\n",
      "AUC =  0.7760416666666667 Loss = 0.8049428221554717 Acc = 0.8\n",
      "--- Fold 19 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 7 FN = 8 FP = 11 TP = 24\n",
      "AUC =  0.6979166666666666 Loss = 1.1181097127917186 Acc = 0.62\n",
      "--- Fold 20 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.6961805555555556 Loss = 1.208452516646772 Acc = 0.66\n",
      "--- Fold 21 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.6857638888888888 Loss = 1.1279326958675175 Acc = 0.7\n",
      "--- Fold 22 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7482638888888888 Loss = 0.9976066771300673 Acc = 0.72\n",
      "--- Fold 23 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7465277777777778 Loss = 1.042135410590499 Acc = 0.72\n",
      "--- Fold 24 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.765625 Loss = 0.8767027766557477 Acc = 0.72\n",
      "--- Fold 25 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 5 FN = 2 FP = 13 TP = 30\n",
      "AUC =  0.6996527777777778 Loss = 1.2096156157459712 Acc = 0.7\n",
      "--- Fold 26 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.7534722222222222 Loss = 0.8890860797952602 Acc = 0.7\n",
      "--- Fold 27 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.765625 Loss = 0.9510741899401469 Acc = 0.66\n",
      "--- Fold 28 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.7586805555555556 Loss = 0.7396038756854986 Acc = 0.74\n",
      "--- Fold 29 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.8020833333333333 Loss = 0.8942214949626064 Acc = 0.72\n",
      "--- Fold 30 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.7586805555555556 Loss = 0.8694940210023155 Acc = 0.7\n",
      "--- Fold 31 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.59375 Loss = 1.7622037773590429 Acc = 0.64\n",
      "--- Fold 32 started at Tue Apr 23 14:27:35 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.6684027777777778 Loss = 1.3432493685618647 Acc = 0.68\n",
      "--- Fold 33 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 11 FN = 4 FP = 7 TP = 28\n",
      "AUC =  0.7899305555555556 Loss = 1.0718591951475605 Acc = 0.78\n",
      "--- Fold 34 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 12 FN = 2 FP = 6 TP = 30\n",
      "AUC =  0.907986111111111 Loss = 0.4503132161509461 Acc = 0.84\n",
      "--- Fold 35 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.8003472222222222 Loss = 0.904086424849555 Acc = 0.74\n",
      "--- Fold 36 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 13 FN = 9 FP = 5 TP = 23\n",
      "AUC =  0.7708333333333334 Loss = 0.9048754749947637 Acc = 0.72\n",
      "--- Fold 37 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.7864583333333333 Loss = 0.9604961313176631 Acc = 0.74\n",
      "--- Fold 38 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.6788194444444444 Loss = 1.346564837865788 Acc = 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 39 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 7 FN = 2 FP = 11 TP = 30\n",
      "AUC =  0.7152777777777778 Loss = 1.0049971196195835 Acc = 0.74\n",
      "--- Fold 40 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.7152777777777778 Loss = 1.2805478665704897 Acc = 0.68\n",
      "--- Fold 41 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 12 FN = 1 FP = 6 TP = 31\n",
      "AUC =  0.8177083333333334 Loss = 0.6988848445866678 Acc = 0.86\n",
      "--- Fold 42 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.7569444444444444 Loss = 1.2490300195606487 Acc = 0.74\n",
      "--- Fold 43 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.7204861111111112 Loss = 1.04231742603915 Acc = 0.68\n",
      "--- Fold 44 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 10 FN = 3 FP = 8 TP = 29\n",
      "AUC =  0.842013888888889 Loss = 0.659670906637343 Acc = 0.78\n",
      "--- Fold 45 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 9 FN = 9 FP = 9 TP = 23\n",
      "AUC =  0.703125 Loss = 1.0749388057505267 Acc = 0.64\n",
      "--- Fold 46 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.6736111111111112 Loss = 1.3307209714690726 Acc = 0.68\n",
      "--- Fold 47 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.7604166666666666 Loss = 1.0791469118683528 Acc = 0.7\n",
      "--- Fold 48 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 8 FN = 2 FP = 10 TP = 30\n",
      "AUC =  0.8211805555555556 Loss = 0.6838443580074859 Acc = 0.76\n",
      "--- Fold 49 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.7552083333333334 Loss = 0.9549608121836947 Acc = 0.7\n",
      "--- Fold 50 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7916666666666666 Loss = 0.7292492772708985 Acc = 0.72\n",
      "--- Fold 51 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 5 FN = 6 FP = 13 TP = 26\n",
      "AUC =  0.6145833333333334 Loss = 1.6480573917334211 Acc = 0.62\n",
      "--- Fold 52 started at Tue Apr 23 14:27:36 2019\n",
      "TN = 9 FN = 6 FP = 9 TP = 26\n",
      "AUC =  0.7152777777777778 Loss = 1.0761878629718107 Acc = 0.7\n",
      "--- Fold 53 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.7847222222222221 Loss = 0.8770152427889237 Acc = 0.7\n",
      "--- Fold 54 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 7 FN = 0 FP = 11 TP = 32\n",
      "AUC =  0.8958333333333335 Loss = 0.6424413742132047 Acc = 0.78\n",
      "--- Fold 55 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 8 FN = 1 FP = 10 TP = 31\n",
      "AUC =  0.8038194444444444 Loss = 0.9061558074004004 Acc = 0.78\n",
      "--- Fold 56 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 10 FN = 4 FP = 8 TP = 28\n",
      "AUC =  0.8194444444444444 Loss = 0.7182054964640651 Acc = 0.76\n",
      "--- Fold 57 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.704861111111111 Loss = 1.2406032157422047 Acc = 0.7\n",
      "--- Fold 58 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.6805555555555556 Loss = 1.132266979131064 Acc = 0.7\n",
      "--- Fold 59 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 7 FN = 4 FP = 11 TP = 28\n",
      "AUC =  0.8298611111111112 Loss = 0.8232236661976304 Acc = 0.7\n",
      "--- Fold 60 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 7 FN = 5 FP = 11 TP = 27\n",
      "AUC =  0.7309027777777778 Loss = 1.12012427162001 Acc = 0.68\n",
      "--- Fold 61 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.6927083333333335 Loss = 1.2134257260923789 Acc = 0.68\n",
      "--- Fold 62 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.625 Loss = 1.2985906831193263 Acc = 0.64\n",
      "--- Fold 63 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 8 FN = 6 FP = 10 TP = 26\n",
      "AUC =  0.7638888888888888 Loss = 1.0793238255267827 Acc = 0.68\n",
      "--- Fold 64 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 8 FN = 2 FP = 10 TP = 30\n",
      "AUC =  0.7465277777777778 Loss = 0.9910136509652284 Acc = 0.76\n",
      "--- Fold 65 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 9 FN = 1 FP = 9 TP = 31\n",
      "AUC =  0.8125 Loss = 0.7039978759773379 Acc = 0.8\n",
      "--- Fold 66 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 4 FN = 6 FP = 14 TP = 26\n",
      "AUC =  0.5815972222222223 Loss = 1.5878006820432982 Acc = 0.6\n",
      "--- Fold 67 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.6996527777777778 Loss = 1.2072525649564878 Acc = 0.74\n",
      "--- Fold 68 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.7673611111111112 Loss = 1.2009281263880507 Acc = 0.7\n",
      "--- Fold 69 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 9 FN = 8 FP = 9 TP = 24\n",
      "AUC =  0.6822916666666666 Loss = 1.215073525589227 Acc = 0.66\n",
      "--- Fold 70 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.6996527777777778 Loss = 1.1612510963297178 Acc = 0.7\n",
      "--- Fold 71 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.6875 Loss = 1.2370094107063536 Acc = 0.72\n",
      "--- Fold 72 started at Tue Apr 23 14:27:37 2019\n",
      "TN = 9 FN = 8 FP = 9 TP = 24\n",
      "AUC =  0.673611111111111 Loss = 1.3599631358622382 Acc = 0.66\n",
      "--- Fold 73 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 11 FN = 5 FP = 7 TP = 27\n",
      "AUC =  0.7916666666666666 Loss = 0.7728504841217101 Acc = 0.76\n",
      "--- Fold 74 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 5 FN = 2 FP = 13 TP = 30\n",
      "AUC =  0.7465277777777779 Loss = 1.3518531905476505 Acc = 0.7\n",
      "--- Fold 75 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7152777777777778 Loss = 1.0566471925206546 Acc = 0.72\n",
      "--- Fold 76 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.7864583333333333 Loss = 1.206812107127689 Acc = 0.7\n",
      "--- Fold 77 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 8 FN = 1 FP = 10 TP = 31\n",
      "AUC =  0.8072916666666667 Loss = 0.8490995093551992 Acc = 0.78\n",
      "--- Fold 78 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 8 FN = 7 FP = 10 TP = 25\n",
      "AUC =  0.6979166666666667 Loss = 1.1496859019730858 Acc = 0.66\n",
      "--- Fold 79 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 8 FN = 2 FP = 10 TP = 30\n",
      "AUC =  0.8038194444444444 Loss = 0.857574524476573 Acc = 0.76\n",
      "--- Fold 80 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.6180555555555556 Loss = 1.463198685346236 Acc = 0.64\n",
      "--- Fold 81 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.6614583333333334 Loss = 1.2681259001399923 Acc = 0.66\n",
      "--- Fold 82 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 9 FN = 7 FP = 9 TP = 25\n",
      "AUC =  0.6996527777777778 Loss = 1.2862337947112132 Acc = 0.68\n",
      "--- Fold 83 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 10 FN = 6 FP = 8 TP = 26\n",
      "AUC =  0.8090277777777778 Loss = 0.8033769570803965 Acc = 0.72\n",
      "--- Fold 84 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 8 FN = 3 FP = 10 TP = 29\n",
      "AUC =  0.7899305555555555 Loss = 0.8600015380928251 Acc = 0.74\n",
      "--- Fold 85 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 7 FN = 6 FP = 11 TP = 26\n",
      "AUC =  0.6927083333333333 Loss = 1.1905771050550356 Acc = 0.66\n",
      "--- Fold 86 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 8 FN = 5 FP = 10 TP = 27\n",
      "AUC =  0.828125 Loss = 0.8928854321246259 Acc = 0.7\n",
      "--- Fold 87 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 10 FN = 3 FP = 8 TP = 29\n",
      "AUC =  0.8385416666666667 Loss = 0.646583892454975 Acc = 0.78\n",
      "--- Fold 88 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 6 FN = 1 FP = 12 TP = 31\n",
      "AUC =  0.7239583333333334 Loss = 1.2498634845944325 Acc = 0.74\n",
      "--- Fold 89 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 5 FN = 5 FP = 13 TP = 27\n",
      "AUC =  0.7291666666666666 Loss = 0.9883551240481258 Acc = 0.64\n",
      "--- Fold 90 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.7760416666666667 Loss = 0.9402040898761945 Acc = 0.74\n",
      "--- Fold 91 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.6631944444444444 Loss = 1.2791417030825605 Acc = 0.66\n",
      "--- Fold 92 started at Tue Apr 23 14:27:38 2019\n",
      "TN = 10 FN = 1 FP = 8 TP = 31\n",
      "AUC =  0.8350694444444444 Loss = 0.6611983573805499 Acc = 0.82\n",
      "--- Fold 93 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.765625 Loss = 0.9648009443449375 Acc = 0.7\n",
      "--- Fold 94 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.6302083333333333 Loss = 1.3289076037047889 Acc = 0.66\n",
      "--- Fold 95 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.6163194444444444 Loss = 1.37986404571831 Acc = 0.68\n",
      "--- Fold 96 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 9 FN = 5 FP = 9 TP = 27\n",
      "AUC =  0.7690972222222222 Loss = 0.8612378915014576 Acc = 0.72\n",
      "--- Fold 97 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 12 FN = 3 FP = 6 TP = 29\n",
      "AUC =  0.8680555555555555 Loss = 0.515250447275958 Acc = 0.82\n",
      "--- Fold 98 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 9 FN = 4 FP = 9 TP = 28\n",
      "AUC =  0.845486111111111 Loss = 0.629881032988088 Acc = 0.74\n",
      "--- Fold 99 started at Tue Apr 23 14:27:39 2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN = 7 FN = 1 FP = 11 TP = 31\n",
      "AUC =  0.8506944444444444 Loss = 0.844262498451506 Acc = 0.76\n",
      "model model_gnb: 0      0.999983\n",
      "1      0.859626\n",
      "2      0.439731\n",
      "3      0.954190\n",
      "4      0.996830\n",
      "5      0.932712\n",
      "6      0.686584\n",
      "7      0.997575\n",
      "8      0.932633\n",
      "9      0.984675\n",
      "10     0.764190\n",
      "11     0.916366\n",
      "12     0.989203\n",
      "13     0.555200\n",
      "14     0.116775\n",
      "15     0.999982\n",
      "16     0.999441\n",
      "17     0.159006\n",
      "18     0.999724\n",
      "19     0.485343\n",
      "20     0.678671\n",
      "21     0.992261\n",
      "22     0.000352\n",
      "23     0.955417\n",
      "24     0.700435\n",
      "25     0.620616\n",
      "26     0.998501\n",
      "27     0.997195\n",
      "28     0.995618\n",
      "29     0.273131\n",
      "         ...   \n",
      "220    0.975703\n",
      "221    0.601997\n",
      "222    0.767470\n",
      "223    0.923775\n",
      "224    0.978348\n",
      "225    0.236202\n",
      "226    0.991448\n",
      "227    0.017935\n",
      "228    0.969537\n",
      "229    0.994599\n",
      "230    0.999813\n",
      "231    0.991715\n",
      "232    0.999937\n",
      "233    0.532586\n",
      "234    0.492478\n",
      "235    0.998037\n",
      "236    0.778166\n",
      "237    0.883447\n",
      "238    0.687331\n",
      "239    0.853231\n",
      "240    0.736248\n",
      "241    0.991897\n",
      "242    0.661880\n",
      "243    0.945137\n",
      "244    0.611992\n",
      "245    0.986226\n",
      "246    0.365710\n",
      "247    0.980046\n",
      "248    0.859241\n",
      "249    0.089163\n",
      "Length: 250, dtype: float64\n",
      "--- Fold 0 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 7 FN = 1 FP = 11 TP = 31\n",
      "AUC =  0.7256944444444444 Loss = 0.5821506563470413 Acc = 0.76\n",
      "--- Fold 1 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 3 FN = 4 FP = 15 TP = 28\n",
      "AUC =  0.515625 Loss = 0.6823587902778665 Acc = 0.62\n",
      "--- Fold 2 started at Tue Apr 23 14:27:39 2019\n",
      "TN = 3 FN = 7 FP = 15 TP = 25\n",
      "AUC =  0.4592013888888889 Loss = 1.405413916710462 Acc = 0.56\n",
      "--- Fold 3 started at Tue Apr 23 14:27:40 2019\n",
      "TN = 1 FN = 4 FP = 17 TP = 28\n",
      "AUC =  0.5989583333333333 Loss = 0.6649242638678844 Acc = 0.58\n",
      "--- Fold 4 started at Tue Apr 23 14:27:40 2019\n",
      "TN = 1 FN = 5 FP = 17 TP = 27\n",
      "AUC =  0.4322916666666667 Loss = 0.7733307869678605 Acc = 0.56\n",
      "--- Fold 5 started at Tue Apr 23 14:27:40 2019\n",
      "TN = 1 FN = 3 FP = 17 TP = 29\n",
      "AUC =  0.5234375000000001 Loss = 0.6835256711240347 Acc = 0.6\n",
      "--- Fold 6 started at Tue Apr 23 14:27:41 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.5885416666666666 Loss = 0.6469276550396558 Acc = 0.64\n",
      "--- Fold 7 started at Tue Apr 23 14:27:41 2019\n",
      "TN = 1 FN = 3 FP = 17 TP = 29\n",
      "AUC =  0.4487847222222222 Loss = 0.7550178758791817 Acc = 0.6\n",
      "--- Fold 8 started at Tue Apr 23 14:27:41 2019\n",
      "TN = 4 FN = 2 FP = 14 TP = 30\n",
      "AUC =  0.609375 Loss = 1.2847204797594975 Acc = 0.68\n",
      "--- Fold 9 started at Tue Apr 23 14:27:41 2019\n",
      "TN = 0 FN = 1 FP = 18 TP = 31\n",
      "AUC =  0.603298611111111 Loss = 1.2995592266540847 Acc = 0.62\n",
      "--- Fold 10 started at Tue Apr 23 14:27:42 2019\n",
      "TN = 2 FN = 1 FP = 16 TP = 31\n",
      "AUC =  0.7534722222222223 Loss = 0.5777768723277448 Acc = 0.66\n",
      "--- Fold 11 started at Tue Apr 23 14:27:42 2019\n",
      "TN = 1 FN = 7 FP = 17 TP = 25\n",
      "AUC =  0.4722222222222222 Loss = 0.760439886993446 Acc = 0.52\n",
      "--- Fold 12 started at Tue Apr 23 14:27:42 2019\n",
      "TN = 1 FN = 6 FP = 17 TP = 26\n",
      "AUC =  0.3715277777777778 Loss = 0.7813639056718406 Acc = 0.54\n",
      "--- Fold 13 started at Tue Apr 23 14:27:43 2019\n",
      "TN = 2 FN = 0 FP = 16 TP = 32\n",
      "AUC =  0.5477430555555556 Loss = 0.6631320206940907 Acc = 0.68\n",
      "--- Fold 14 started at Tue Apr 23 14:27:43 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.6493055555555556 Loss = 0.6141671476539355 Acc = 0.7\n",
      "--- Fold 15 started at Tue Apr 23 14:27:43 2019\n",
      "TN = 1 FN = 7 FP = 17 TP = 25\n",
      "AUC =  0.4704861111111111 Loss = 0.7941845292602591 Acc = 0.52\n",
      "--- Fold 16 started at Tue Apr 23 14:27:43 2019\n",
      "TN = 3 FN = 4 FP = 15 TP = 28\n",
      "AUC =  0.5460069444444444 Loss = 0.6956666479474357 Acc = 0.62\n",
      "--- Fold 17 started at Tue Apr 23 14:27:44 2019\n",
      "TN = 2 FN = 3 FP = 16 TP = 29\n",
      "AUC =  0.5156250000000001 Loss = 0.6788846260837752 Acc = 0.62\n",
      "--- Fold 18 started at Tue Apr 23 14:27:44 2019\n",
      "TN = 1 FN = 8 FP = 17 TP = 24\n",
      "AUC =  0.5572916666666667 Loss = 0.6869190799088426 Acc = 0.5\n",
      "--- Fold 19 started at Tue Apr 23 14:27:44 2019\n",
      "TN = 3 FN = 5 FP = 15 TP = 27\n",
      "AUC =  0.5390625 Loss = 0.7010124756035168 Acc = 0.6\n",
      "--- Fold 20 started at Tue Apr 23 14:27:45 2019\n",
      "TN = 2 FN = 3 FP = 16 TP = 29\n",
      "AUC =  0.6319444444444444 Loss = 1.3081042971323944 Acc = 0.62\n",
      "--- Fold 21 started at Tue Apr 23 14:27:45 2019\n",
      "TN = 0 FN = 5 FP = 18 TP = 27\n",
      "AUC =  0.36111111111111116 Loss = 0.7764848892548971 Acc = 0.54\n",
      "--- Fold 22 started at Tue Apr 23 14:27:45 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.5598958333333334 Loss = 0.6996326181737778 Acc = 0.64\n",
      "--- Fold 23 started at Tue Apr 23 14:27:45 2019\n",
      "TN = 2 FN = 6 FP = 16 TP = 26\n",
      "AUC =  0.509548611111111 Loss = 0.6990871989509398 Acc = 0.56\n",
      "--- Fold 24 started at Tue Apr 23 14:27:46 2019\n",
      "TN = 2 FN = 6 FP = 16 TP = 26\n",
      "AUC =  0.4748263888888889 Loss = 0.729884008525574 Acc = 0.56\n",
      "--- Fold 25 started at Tue Apr 23 14:27:46 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.548611111111111 Loss = 0.6767736561240144 Acc = 0.64\n",
      "--- Fold 26 started at Tue Apr 23 14:27:46 2019\n",
      "TN = 1 FN = 2 FP = 17 TP = 30\n",
      "AUC =  0.546875 Loss = 0.6752834765407791 Acc = 0.62\n",
      "--- Fold 27 started at Tue Apr 23 14:27:47 2019\n",
      "TN = 3 FN = 5 FP = 15 TP = 27\n",
      "AUC =  0.5347222222222222 Loss = 0.690383577384142 Acc = 0.6\n",
      "--- Fold 28 started at Tue Apr 23 14:27:47 2019\n",
      "TN = 2 FN = 3 FP = 16 TP = 29\n",
      "AUC =  0.4487847222222222 Loss = 0.726809326526733 Acc = 0.62\n",
      "--- Fold 29 started at Tue Apr 23 14:27:47 2019\n",
      "TN = 1 FN = 3 FP = 17 TP = 29\n",
      "AUC =  0.515625 Loss = 0.7048454123510755 Acc = 0.6\n",
      "--- Fold 30 started at Tue Apr 23 14:27:47 2019\n",
      "TN = 2 FN = 4 FP = 16 TP = 28\n",
      "AUC =  0.5147569444444444 Loss = 1.3522475265927982 Acc = 0.6\n",
      "--- Fold 31 started at Tue Apr 23 14:27:48 2019\n",
      "TN = 6 FN = 5 FP = 12 TP = 27\n",
      "AUC =  0.5477430555555556 Loss = 0.6989943522973476 Acc = 0.66\n",
      "--- Fold 32 started at Tue Apr 23 14:27:48 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.5894097222222222 Loss = 0.6437910282525233 Acc = 0.66\n",
      "--- Fold 33 started at Tue Apr 23 14:27:48 2019\n",
      "TN = 7 FN = 3 FP = 11 TP = 29\n",
      "AUC =  0.6788194444444444 Loss = 0.6104482927064775 Acc = 0.72\n",
      "--- Fold 34 started at Tue Apr 23 14:27:49 2019\n",
      "TN = 4 FN = 3 FP = 14 TP = 29\n",
      "AUC =  0.6206597222222222 Loss = 0.6535680127650924 Acc = 0.66\n",
      "--- Fold 35 started at Tue Apr 23 14:27:49 2019\n",
      "TN = 4 FN = 2 FP = 14 TP = 30\n",
      "AUC =  0.5347222222222222 Loss = 1.3680620767707745 Acc = 0.68\n",
      "--- Fold 36 started at Tue Apr 23 14:27:49 2019\n",
      "TN = 6 FN = 7 FP = 12 TP = 25\n",
      "AUC =  0.5868055555555556 Loss = 0.6664822953115985 Acc = 0.62\n",
      "--- Fold 37 started at Tue Apr 23 14:27:49 2019\n",
      "TN = 2 FN = 4 FP = 16 TP = 28\n",
      "AUC =  0.5868055555555556 Loss = 0.6428900733062305 Acc = 0.6\n",
      "--- Fold 38 started at Tue Apr 23 14:27:50 2019\n",
      "TN = 2 FN = 3 FP = 16 TP = 29\n",
      "AUC =  0.59375 Loss = 0.6506715047802267 Acc = 0.62\n",
      "--- Fold 39 started at Tue Apr 23 14:27:50 2019\n",
      "TN = 2 FN = 2 FP = 16 TP = 30\n",
      "AUC =  0.484375 Loss = 0.7039315538559784 Acc = 0.64\n",
      "--- Fold 40 started at Tue Apr 23 14:27:50 2019\n",
      "TN = 3 FN = 2 FP = 15 TP = 30\n",
      "AUC =  0.609375 Loss = 0.6454624702495334 Acc = 0.66\n",
      "--- Fold 41 started at Tue Apr 23 14:27:51 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.6354166666666666 Loss = 0.6301539647736997 Acc = 0.68\n",
      "--- Fold 42 started at Tue Apr 23 14:27:51 2019\n",
      "TN = 5 FN = 2 FP = 13 TP = 30\n",
      "AUC =  0.5286458333333334 Loss = 1.3633236131258233 Acc = 0.7\n",
      "--- Fold 43 started at Tue Apr 23 14:27:51 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.6059027777777779 Loss = 0.6273859183165172 Acc = 0.64\n",
      "--- Fold 44 started at Tue Apr 23 14:27:51 2019\n",
      "TN = 5 FN = 6 FP = 13 TP = 26\n",
      "AUC =  0.6875 Loss = 0.6128265236872011 Acc = 0.62\n",
      "--- Fold 45 started at Tue Apr 23 14:27:52 2019\n",
      "TN = 1 FN = 4 FP = 17 TP = 28\n",
      "AUC =  0.4635416666666667 Loss = 0.7413724808026536 Acc = 0.58\n",
      "--- Fold 46 started at Tue Apr 23 14:27:52 2019\n",
      "TN = 3 FN = 2 FP = 15 TP = 30\n",
      "AUC =  0.5772569444444444 Loss = 0.6381122351405836 Acc = 0.66\n",
      "--- Fold 47 started at Tue Apr 23 14:27:52 2019\n",
      "TN = 6 FN = 7 FP = 12 TP = 25\n",
      "AUC =  0.537326388888889 Loss = 0.6900686102447794 Acc = 0.62\n",
      "--- Fold 48 started at Tue Apr 23 14:27:53 2019\n",
      "TN = 3 FN = 0 FP = 15 TP = 32\n",
      "AUC =  0.6267361111111112 Loss = 0.6336364605654952 Acc = 0.7\n",
      "--- Fold 49 started at Tue Apr 23 14:27:53 2019\n",
      "TN = 3 FN = 2 FP = 15 TP = 30\n",
      "AUC =  0.5789930555555556 Loss = 0.6488733545342457 Acc = 0.66\n",
      "--- Fold 50 started at Tue Apr 23 14:27:53 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.5555555555555556 Loss = 1.3248403661563675 Acc = 0.68\n",
      "--- Fold 51 started at Tue Apr 23 14:27:53 2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN = 6 FN = 6 FP = 12 TP = 26\n",
      "AUC =  0.5850694444444444 Loss = 0.7193170550944913 Acc = 0.64\n",
      "--- Fold 52 started at Tue Apr 23 14:27:54 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.4852430555555556 Loss = 0.7096768637073096 Acc = 0.64\n",
      "--- Fold 53 started at Tue Apr 23 14:27:54 2019\n",
      "TN = 1 FN = 4 FP = 17 TP = 28\n",
      "AUC =  0.6223958333333333 Loss = 0.6512394942706606 Acc = 0.58\n",
      "--- Fold 54 started at Tue Apr 23 14:27:54 2019\n",
      "TN = 3 FN = 3 FP = 15 TP = 29\n",
      "AUC =  0.5659722222222222 Loss = 0.6742494881157032 Acc = 0.64\n",
      "--- Fold 55 started at Tue Apr 23 14:27:54 2019\n",
      "TN = 0 FN = 4 FP = 18 TP = 28\n",
      "AUC =  0.3550347222222222 Loss = 1.4406191718162977 Acc = 0.56\n",
      "--- Fold 56 started at Tue Apr 23 14:27:55 2019\n",
      "TN = 5 FN = 2 FP = 13 TP = 30\n",
      "AUC =  0.6762152777777778 Loss = 0.601549692872605 Acc = 0.7\n",
      "--- Fold 57 started at Tue Apr 23 14:27:55 2019\n",
      "TN = 1 FN = 7 FP = 17 TP = 25\n",
      "AUC =  0.4852430555555556 Loss = 0.7082388211358831 Acc = 0.52\n",
      "--- Fold 58 started at Tue Apr 23 14:27:55 2019\n",
      "TN = 2 FN = 5 FP = 16 TP = 27\n",
      "AUC =  0.5963541666666666 Loss = 0.6428771697574263 Acc = 0.58\n",
      "--- Fold 59 started at Tue Apr 23 14:27:55 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.5972222222222222 Loss = 0.6622453044176896 Acc = 0.64\n",
      "--- Fold 60 started at Tue Apr 23 14:27:56 2019\n",
      "TN = 3 FN = 5 FP = 15 TP = 27\n",
      "AUC =  0.59375 Loss = 0.659769513774583 Acc = 0.6\n",
      "--- Fold 61 started at Tue Apr 23 14:27:56 2019\n",
      "TN = 2 FN = 6 FP = 16 TP = 26\n",
      "AUC =  0.599826388888889 Loss = 0.6668055940486657 Acc = 0.56\n",
      "--- Fold 62 started at Tue Apr 23 14:27:56 2019\n",
      "TN = 4 FN = 4 FP = 14 TP = 28\n",
      "AUC =  0.5842013888888888 Loss = 0.6726566541023932 Acc = 0.64\n",
      "--- Fold 63 started at Tue Apr 23 14:27:57 2019\n",
      "TN = 1 FN = 5 FP = 17 TP = 27\n",
      "AUC =  0.5911458333333333 Loss = 0.6719912460072675 Acc = 0.56\n",
      "--- Fold 64 started at Tue Apr 23 14:27:57 2019\n",
      "TN = 4 FN = 0 FP = 14 TP = 32\n",
      "AUC =  0.732638888888889 Loss = 0.558891399797532 Acc = 0.72\n",
      "--- Fold 65 started at Tue Apr 23 14:27:57 2019\n",
      "TN = 3 FN = 4 FP = 15 TP = 28\n",
      "AUC =  0.5729166666666666 Loss = 0.6647565688771965 Acc = 0.62\n",
      "--- Fold 66 started at Tue Apr 23 14:27:57 2019\n",
      "TN = 1 FN = 3 FP = 17 TP = 29\n",
      "AUC =  0.5581597222222222 Loss = 0.651247825868365 Acc = 0.6\n",
      "--- Fold 67 started at Tue Apr 23 14:27:58 2019\n",
      "TN = 2 FN = 4 FP = 16 TP = 28\n",
      "AUC =  0.4253472222222222 Loss = 0.7575291403386886 Acc = 0.6\n",
      "--- Fold 68 started at Tue Apr 23 14:27:58 2019\n",
      "TN = 4 FN = 1 FP = 14 TP = 31\n",
      "AUC =  0.5572916666666666 Loss = 0.682597573959046 Acc = 0.7\n",
      "--- Fold 69 started at Tue Apr 23 14:27:58 2019\n",
      "TN = 2 FN = 6 FP = 16 TP = 26\n",
      "AUC =  0.5095486111111112 Loss = 0.7005335731200704 Acc = 0.56\n",
      "--- Fold 70 started at Tue Apr 23 14:27:59 2019\n",
      "TN = 2 FN = 5 FP = 16 TP = 27\n",
      "AUC =  0.5164930555555556 Loss = 0.6914484676745184 Acc = 0.58\n",
      "--- Fold 71 started at Tue Apr 23 14:27:59 2019\n",
      "TN = 4 FN = 7 FP = 14 TP = 25\n",
      "AUC =  0.5173611111111112 Loss = 0.6964830878378409 Acc = 0.58\n",
      "--- Fold 72 started at Tue Apr 23 14:27:59 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.5911458333333333 Loss = 0.6643608463285505 Acc = 0.68\n",
      "--- Fold 73 started at Tue Apr 23 14:27:59 2019\n",
      "TN = 5 FN = 3 FP = 13 TP = 29\n",
      "AUC =  0.5824652777777778 Loss = 0.6817146173292492 Acc = 0.68\n",
      "--- Fold 74 started at Tue Apr 23 14:28:00 2019\n",
      "TN = 2 FN = 0 FP = 16 TP = 32\n",
      "AUC =  0.6241319444444444 Loss = 0.6370344413014031 Acc = 0.68\n",
      "--- Fold 75 started at Tue Apr 23 14:28:00 2019\n",
      "TN = 3 FN = 6 FP = 15 TP = 26\n",
      "AUC =  0.46701388888888884 Loss = 0.728827449832902 Acc = 0.58\n",
      "--- Fold 76 started at Tue Apr 23 14:28:00 2019\n",
      "TN = 2 FN = 1 FP = 16 TP = 31\n",
      "AUC =  0.6666666666666666 Loss = 0.6108523468528277 Acc = 0.66\n",
      "--- Fold 77 started at Tue Apr 23 14:28:01 2019\n",
      "TN = 6 FN = 4 FP = 12 TP = 28\n",
      "AUC =  0.5703125 Loss = 1.3155068103108443 Acc = 0.68\n",
      "--- Fold 78 started at Tue Apr 23 14:28:01 2019\n",
      "TN = 6 FN = 3 FP = 12 TP = 29\n",
      "AUC =  0.5980902777777779 Loss = 0.6505907493709435 Acc = 0.7\n",
      "--- Fold 79 started at Tue Apr 23 14:28:01 2019\n",
      "TN = 6 FN = 1 FP = 12 TP = 31\n",
      "AUC =  0.7690972222222223 Loss = 0.5513643257956944 Acc = 0.74\n",
      "--- Fold 80 started at Tue Apr 23 14:28:01 2019\n",
      "TN = 3 FN = 5 FP = 15 TP = 27\n",
      "AUC =  0.5026041666666666 Loss = 0.7005335731200704 Acc = 0.6\n",
      "--- Fold 81 started at Tue Apr 23 14:28:02 2019\n",
      "TN = 1 FN = 3 FP = 17 TP = 29\n",
      "AUC =  0.5642361111111112 Loss = 1.3265971355137611 Acc = 0.6\n",
      "--- Fold 82 started at Tue Apr 23 14:28:02 2019\n",
      "TN = 3 FN = 8 FP = 15 TP = 24\n",
      "AUC =  0.46875 Loss = 0.7223547870981534 Acc = 0.54\n",
      "--- Fold 83 started at Tue Apr 23 14:28:02 2019\n",
      "TN = 2 FN = 1 FP = 16 TP = 31\n",
      "AUC =  0.71875 Loss = 0.5819202042635662 Acc = 0.66\n",
      "--- Fold 84 started at Tue Apr 23 14:28:03 2019\n",
      "TN = 0 FN = 2 FP = 18 TP = 30\n",
      "AUC =  0.6510416666666666 Loss = 0.6321946583474645 Acc = 0.6\n",
      "--- Fold 85 started at Tue Apr 23 14:28:03 2019\n",
      "TN = 2 FN = 0 FP = 16 TP = 32\n",
      "AUC =  0.6770833333333334 Loss = 0.6005467473705204 Acc = 0.68\n",
      "--- Fold 86 started at Tue Apr 23 14:28:03 2019\n",
      "TN = 3 FN = 4 FP = 15 TP = 28\n",
      "AUC =  0.6163194444444444 Loss = 0.6534977363790965 Acc = 0.62\n",
      "--- Fold 87 started at Tue Apr 23 14:28:04 2019\n",
      "TN = 2 FN = 5 FP = 16 TP = 27\n",
      "AUC =  0.5164930555555556 Loss = 0.7052448945463258 Acc = 0.58\n",
      "--- Fold 88 started at Tue Apr 23 14:28:04 2019\n",
      "TN = 5 FN = 4 FP = 13 TP = 28\n",
      "AUC =  0.5954861111111112 Loss = 0.6258466974937946 Acc = 0.66\n",
      "--- Fold 89 started at Tue Apr 23 14:28:04 2019\n",
      "TN = 3 FN = 4 FP = 15 TP = 28\n",
      "AUC =  0.47829861111111116 Loss = 0.7340131017915038 Acc = 0.62\n",
      "--- Fold 90 started at Tue Apr 23 14:28:04 2019\n",
      "TN = 2 FN = 0 FP = 16 TP = 32\n",
      "AUC =  0.6519097222222222 Loss = 0.603147098837015 Acc = 0.68\n",
      "--- Fold 91 started at Tue Apr 23 14:28:05 2019\n",
      "TN = 1 FN = 7 FP = 17 TP = 25\n",
      "AUC =  0.4140625 Loss = 1.3899406635860492 Acc = 0.52\n",
      "--- Fold 92 started at Tue Apr 23 14:28:05 2019\n",
      "TN = 2 FN = 3 FP = 16 TP = 29\n",
      "AUC =  0.681423611111111 Loss = 0.6051070370014966 Acc = 0.62\n",
      "--- Fold 93 started at Tue Apr 23 14:28:05 2019\n",
      "TN = 3 FN = 6 FP = 15 TP = 26\n",
      "AUC =  0.6519097222222223 Loss = 0.6493807343574752 Acc = 0.58\n",
      "--- Fold 94 started at Tue Apr 23 14:28:06 2019\n",
      "TN = 3 FN = 5 FP = 15 TP = 27\n",
      "AUC =  0.45138888888888884 Loss = 0.7576756001828678 Acc = 0.6\n",
      "--- Fold 95 started at Tue Apr 23 14:28:06 2019\n",
      "TN = 1 FN = 3 FP = 17 TP = 29\n",
      "AUC =  0.5286458333333334 Loss = 0.7292352636258568 Acc = 0.6\n",
      "--- Fold 96 started at Tue Apr 23 14:28:06 2019\n",
      "TN = 1 FN = 1 FP = 17 TP = 31\n",
      "AUC =  0.5902777777777778 Loss = 0.6570859823732883 Acc = 0.64\n",
      "--- Fold 97 started at Tue Apr 23 14:28:06 2019\n",
      "TN = 4 FN = 2 FP = 14 TP = 30\n",
      "AUC =  0.6493055555555556 Loss = 1.2661545463197477 Acc = 0.68\n",
      "--- Fold 98 started at Tue Apr 23 14:28:07 2019\n",
      "TN = 2 FN = 4 FP = 16 TP = 28\n",
      "AUC =  0.5625 Loss = 0.6737834891810611 Acc = 0.6\n",
      "--- Fold 99 started at Tue Apr 23 14:28:07 2019\n",
      "TN = 3 FN = 4 FP = 15 TP = 28\n",
      "AUC =  0.6302083333333334 Loss = 0.6688191454037348 Acc = 0.62\n",
      "model model_rf: 0      0.670\n",
      "1      0.600\n",
      "2      0.665\n",
      "3      0.700\n",
      "4      0.645\n",
      "5      0.625\n",
      "6      0.555\n",
      "7      0.690\n",
      "8      0.680\n",
      "9      0.595\n",
      "10     0.610\n",
      "11     0.660\n",
      "12     0.705\n",
      "13     0.620\n",
      "14     0.610\n",
      "15     0.705\n",
      "16     0.700\n",
      "17     0.610\n",
      "18     0.740\n",
      "19     0.635\n",
      "20     0.620\n",
      "21     0.680\n",
      "22     0.425\n",
      "23     0.600\n",
      "24     0.565\n",
      "25     0.620\n",
      "26     0.625\n",
      "27     0.650\n",
      "28     0.640\n",
      "29     0.540\n",
      "       ...  \n",
      "220    0.620\n",
      "221    0.650\n",
      "222    0.570\n",
      "223    0.610\n",
      "224    0.675\n",
      "225    0.575\n",
      "226    0.725\n",
      "227    0.560\n",
      "228    0.575\n",
      "229    0.650\n",
      "230    0.585\n",
      "231    0.680\n",
      "232    0.670\n",
      "233    0.630\n",
      "234    0.575\n",
      "235    0.615\n",
      "236    0.495\n",
      "237    0.660\n",
      "238    0.625\n",
      "239    0.595\n",
      "240    0.675\n",
      "241    0.715\n",
      "242    0.670\n",
      "243    0.615\n",
      "244    0.630\n",
      "245    0.585\n",
      "246    0.630\n",
      "247    0.685\n",
      "248    0.540\n",
      "249    0.585\n",
      "Length: 250, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "base_models_preds_train = get_fitted_models_and_preds(selected_df, train_labels, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model_lgbm  model_xgb  model_lr  model_gnb  model_rf\n",
      "0    0.861938   0.779973  0.809531   0.999983     0.670\n",
      "1    0.728672   0.657229  0.328080   0.859626     0.600\n",
      "2    0.959275   0.938668  0.844999   0.439731     0.665\n",
      "3    0.751621   0.715920  0.572648   0.954190     0.700\n",
      "4    0.877490   0.862532  0.736097   0.996830     0.645\n",
      "(250, 5)\n",
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "df_base_model_preds_train = pd.DataFrame({base_model_pred_train['classifier']:base_model_pred_train['preds'] for base_model_pred_train in base_models_preds_train})\n",
    "print(df_base_model_preds_train.head())\n",
    "print(df_base_model_preds_train.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_classifier_gbm = XGBClassifier(\n",
    " #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1)\n",
    "\n",
    "second_level_model= second_level_classifier_gbm.fit(df_base_model_preds_train, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98454267 0.05429565 0.9625242  0.8984929  0.98568046 0.9867444\n",
      " 0.9752167  0.97724736 0.88055414 0.9276699  0.09741303 0.9445413\n",
      " 0.99181986 0.08113531 0.18909574 0.98956853 0.98956853 0.13273615\n",
      " 0.98855186 0.918419   0.95006216 0.961518   0.04888226 0.656935\n",
      " 0.79858226 0.90461266 0.975299   0.9795434  0.95588994 0.8790109\n",
      " 0.91264445 0.87388086 0.93710166 0.8843789  0.92010486 0.6676246\n",
      " 0.9498031  0.95180786 0.08420305 0.40821382 0.98855186 0.84304637\n",
      " 0.8851698  0.06614294 0.9494906  0.97762764 0.987828   0.7717624\n",
      " 0.01648152 0.14868811 0.5306824  0.97505015 0.26702285 0.9699897\n",
      " 0.7255793  0.87854284 0.02527561 0.7419575  0.01043171 0.10255012\n",
      " 0.9445498  0.8072452  0.45622554 0.09726931 0.3419839  0.89755297\n",
      " 0.34189585 0.97301847 0.9975182  0.89869404 0.05363849 0.98956853\n",
      " 0.94288844 0.9750864  0.69785106 0.12871987 0.98855186 0.95611525\n",
      " 0.161257   0.80154073 0.8918118  0.19663109 0.3248211  0.97605443\n",
      " 0.9395887  0.851831   0.1289927  0.6788579  0.9565654  0.98774314\n",
      " 0.9862721  0.00738561 0.8749803  0.8275698  0.9876589  0.9894851\n",
      " 0.1582661  0.974661   0.9103298  0.98855186 0.9735642  0.04055017\n",
      " 0.04888226 0.99322706 0.16708559 0.9850272  0.96669334 0.0295997\n",
      " 0.27207106 0.99347806 0.90734845 0.8993926  0.9563377  0.971959\n",
      " 0.18792668 0.94788504 0.98509026 0.17916355 0.20068744 0.9921692\n",
      " 0.03033892 0.92393994 0.06168177 0.91767013 0.15502022 0.9957557\n",
      " 0.69789016 0.05271282 0.01791319 0.88019776 0.85704637 0.7695464\n",
      " 0.7842463  0.99000543 0.2806612  0.8696925  0.16420837 0.92449236\n",
      " 0.9841727  0.12170667 0.91276026 0.16880803 0.97506297 0.12501831\n",
      " 0.96580786 0.8413235  0.98981595 0.88996965 0.01454465 0.97861916\n",
      " 0.26413548 0.99670273 0.9657826  0.13912006 0.18761823 0.9843031\n",
      " 0.8736395  0.1548428  0.22579402 0.9548547  0.9708028  0.02584911\n",
      " 0.98956853 0.9959133  0.17792311 0.9848958  0.9287989  0.96146685\n",
      " 0.11602886 0.42607942 0.07314511 0.0139313  0.1814377  0.8494476\n",
      " 0.96362287 0.9701541  0.98855186 0.04273927 0.04070111 0.95164114\n",
      " 0.8458643  0.15583631 0.00707469 0.14583339 0.8035334  0.8794576\n",
      " 0.9413898  0.83891624 0.8269266  0.23867981 0.813375   0.98282003\n",
      " 0.88382524 0.26660135 0.08468956 0.9906826  0.7004853  0.9698486\n",
      " 0.02443439 0.98956853 0.9905285  0.10719213 0.9242206  0.98855186\n",
      " 0.9954005  0.19729683 0.5535273  0.114317   0.7661297  0.02868672\n",
      " 0.2640583  0.12710233 0.07569316 0.9884862  0.78693277 0.14598455\n",
      " 0.9199879  0.9605516  0.06914055 0.99230933 0.983555   0.98419976\n",
      " 0.9973648  0.9263173  0.9415418  0.01815652 0.99372697 0.04257496\n",
      " 0.2720697  0.99395543 0.8358586  0.992542   0.98669434 0.11195092\n",
      " 0.02412763 0.9082154  0.9995296  0.99827385 0.99046046 0.04432828\n",
      " 0.1631286  0.89789927 0.962675   0.12015364 0.17498077 0.23078707\n",
      " 0.06887361 0.04549594 0.99469864 0.01596308]\n",
      "0.9988194444444445\n"
     ]
    }
   ],
   "source": [
    "ensemble_preds_train = second_level_model.predict_proba(df_base_model_preds_train)\n",
    "print(ensemble_preds_train[:,1])\n",
    "ensemble_preds_score = roc_auc_score(train_labels, ensemble_preds_train[:,1])\n",
    "print(ensemble_preds_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "[0.85148202 0.86342688 0.5768221  ... 0.37541594 0.9843671  0.72744159]\n",
      "0        0.851482\n",
      "1        0.863427\n",
      "2        0.576822\n",
      "3        0.994141\n",
      "4        0.874714\n",
      "5        0.715654\n",
      "6        0.544930\n",
      "7        0.257953\n",
      "8        0.987893\n",
      "9        0.640657\n",
      "10       0.966319\n",
      "11       0.512569\n",
      "12       0.254850\n",
      "13       0.934423\n",
      "14       0.415954\n",
      "15       0.985765\n",
      "16       0.557227\n",
      "17       0.842163\n",
      "18       0.466471\n",
      "19       0.764775\n",
      "20       0.212064\n",
      "21       0.881634\n",
      "22       0.701399\n",
      "23       0.492596\n",
      "24       0.396034\n",
      "25       0.937271\n",
      "26       0.291753\n",
      "27       0.901517\n",
      "28       0.987991\n",
      "29       0.960306\n",
      "           ...   \n",
      "19720    0.870668\n",
      "19721    0.930004\n",
      "19722    0.862305\n",
      "19723    0.052884\n",
      "19724    0.984390\n",
      "19725    0.203997\n",
      "19726    0.976387\n",
      "19727    0.930989\n",
      "19728    0.742029\n",
      "19729    0.950512\n",
      "19730    0.914559\n",
      "19731    0.161911\n",
      "19732    0.928817\n",
      "19733    0.522341\n",
      "19734    0.796814\n",
      "19735    0.362361\n",
      "19736    0.717455\n",
      "19737    0.958586\n",
      "19738    0.972767\n",
      "19739    0.769036\n",
      "19740    0.924853\n",
      "19741    0.952210\n",
      "19742    0.939629\n",
      "19743    0.343974\n",
      "19744    0.983541\n",
      "19745    0.956976\n",
      "19746    0.988301\n",
      "19747    0.375416\n",
      "19748    0.984367\n",
      "19749    0.727442\n",
      "Length: 19750, dtype: float64\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "[0.3526622 0.7857314 0.7988676 ... 0.5368639 0.9791511 0.4283967]\n",
      "0        0.352662\n",
      "1        0.785731\n",
      "2        0.798868\n",
      "3        0.986622\n",
      "4        0.686413\n",
      "5        0.336104\n",
      "6        0.558781\n",
      "7        0.212623\n",
      "8        0.966610\n",
      "9        0.734070\n",
      "10       0.614487\n",
      "11       0.428332\n",
      "12       0.493507\n",
      "13       0.788672\n",
      "14       0.593235\n",
      "15       0.939741\n",
      "16       0.601931\n",
      "17       0.571842\n",
      "18       0.596406\n",
      "19       0.163729\n",
      "20       0.533242\n",
      "21       0.694809\n",
      "22       0.840170\n",
      "23       0.332898\n",
      "24       0.372093\n",
      "25       0.939011\n",
      "26       0.212753\n",
      "27       0.851979\n",
      "28       0.932168\n",
      "29       0.942935\n",
      "           ...   \n",
      "19720    0.694353\n",
      "19721    0.978316\n",
      "19722    0.735939\n",
      "19723    0.143124\n",
      "19724    0.972417\n",
      "19725    0.425130\n",
      "19726    0.773912\n",
      "19727    0.645054\n",
      "19728    0.830833\n",
      "19729    0.638408\n",
      "19730    0.384611\n",
      "19731    0.439083\n",
      "19732    0.954431\n",
      "19733    0.672409\n",
      "19734    0.776611\n",
      "19735    0.547139\n",
      "19736    0.606188\n",
      "19737    0.712105\n",
      "19738    0.929456\n",
      "19739    0.533358\n",
      "19740    0.941153\n",
      "19741    0.910683\n",
      "19742    0.388921\n",
      "19743    0.534967\n",
      "19744    0.927215\n",
      "19745    0.923754\n",
      "19746    0.976764\n",
      "19747    0.536864\n",
      "19748    0.979151\n",
      "19749    0.428397\n",
      "Length: 19750, dtype: float32\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "[0.70589669 0.50490117 0.84395019 ... 0.42624978 0.92215524 0.16152893]\n",
      "0        0.705897\n",
      "1        0.504901\n",
      "2        0.843950\n",
      "3        0.874679\n",
      "4        0.826971\n",
      "5        0.358530\n",
      "6        0.196340\n",
      "7        0.189119\n",
      "8        0.727899\n",
      "9        0.158370\n",
      "10       0.724241\n",
      "11       0.495848\n",
      "12       0.494907\n",
      "13       0.520099\n",
      "14       0.227477\n",
      "15       0.830090\n",
      "16       0.631469\n",
      "17       0.790139\n",
      "18       0.711028\n",
      "19       0.345350\n",
      "20       0.410858\n",
      "21       0.671003\n",
      "22       0.526027\n",
      "23       0.628189\n",
      "24       0.319130\n",
      "25       0.520741\n",
      "26       0.021505\n",
      "27       0.874636\n",
      "28       0.718301\n",
      "29       0.852119\n",
      "           ...   \n",
      "19720    0.351473\n",
      "19721    0.950206\n",
      "19722    0.646834\n",
      "19723    0.051144\n",
      "19724    0.714908\n",
      "19725    0.592237\n",
      "19726    0.937944\n",
      "19727    0.657052\n",
      "19728    0.698263\n",
      "19729    0.922234\n",
      "19730    0.295532\n",
      "19731    0.161059\n",
      "19732    0.849946\n",
      "19733    0.364925\n",
      "19734    0.898277\n",
      "19735    0.564060\n",
      "19736    0.843222\n",
      "19737    0.794930\n",
      "19738    0.916064\n",
      "19739    0.707413\n",
      "19740    0.616709\n",
      "19741    0.724355\n",
      "19742    0.424083\n",
      "19743    0.082458\n",
      "19744    0.905288\n",
      "19745    0.604571\n",
      "19746    0.984851\n",
      "19747    0.426250\n",
      "19748    0.922155\n",
      "19749    0.161529\n",
      "Length: 19750, dtype: float64\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "[0.91705897 0.62522415 0.96293096 ... 0.50368551 0.93895799 0.23409959]\n",
      "0        0.917059\n",
      "1        0.625224\n",
      "2        0.962931\n",
      "3        0.999665\n",
      "4        0.692121\n",
      "5        0.977410\n",
      "6        0.023366\n",
      "7        0.948882\n",
      "8        0.988889\n",
      "9        0.124102\n",
      "10       0.872082\n",
      "11       0.154682\n",
      "12       0.968297\n",
      "13       0.783914\n",
      "14       0.923330\n",
      "15       0.850566\n",
      "16       0.999968\n",
      "17       0.013894\n",
      "18       0.447891\n",
      "19       0.991005\n",
      "20       0.001864\n",
      "21       0.999923\n",
      "22       0.981774\n",
      "23       0.182206\n",
      "24       0.996874\n",
      "25       0.997129\n",
      "26       0.603489\n",
      "27       0.998887\n",
      "28       0.992001\n",
      "29       0.989188\n",
      "           ...   \n",
      "19720    0.349377\n",
      "19721    0.194762\n",
      "19722    0.999920\n",
      "19723    0.060479\n",
      "19724    0.829289\n",
      "19725    0.194978\n",
      "19726    0.712422\n",
      "19727    0.999558\n",
      "19728    0.814810\n",
      "19729    0.999661\n",
      "19730    0.064967\n",
      "19731    0.989532\n",
      "19732    0.998521\n",
      "19733    0.126464\n",
      "19734    0.995265\n",
      "19735    0.546209\n",
      "19736    0.985502\n",
      "19737    0.999939\n",
      "19738    0.999879\n",
      "19739    0.998808\n",
      "19740    0.534311\n",
      "19741    0.996443\n",
      "19742    0.603071\n",
      "19743    0.982461\n",
      "19744    0.996927\n",
      "19745    0.059395\n",
      "19746    0.998886\n",
      "19747    0.503686\n",
      "19748    0.938958\n",
      "19749    0.234100\n",
      "Length: 19750, dtype: float64\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "[0.9 0.8 0.9 ... 0.4 0.6 0.6]\n",
      "0        0.9\n",
      "1        0.8\n",
      "2        0.9\n",
      "3        0.9\n",
      "4        0.4\n",
      "5        0.6\n",
      "6        0.8\n",
      "7        0.5\n",
      "8        0.7\n",
      "9        0.5\n",
      "10       0.5\n",
      "11       0.7\n",
      "12       0.7\n",
      "13       0.7\n",
      "14       0.7\n",
      "15       0.8\n",
      "16       0.6\n",
      "17       0.5\n",
      "18       0.6\n",
      "19       0.5\n",
      "20       0.6\n",
      "21       0.8\n",
      "22       0.9\n",
      "23       0.7\n",
      "24       0.7\n",
      "25       0.7\n",
      "26       0.7\n",
      "27       1.0\n",
      "28       0.8\n",
      "29       0.8\n",
      "        ... \n",
      "19720    0.3\n",
      "19721    0.4\n",
      "19722    0.8\n",
      "19723    0.3\n",
      "19724    0.7\n",
      "19725    0.7\n",
      "19726    0.5\n",
      "19727    0.4\n",
      "19728    0.6\n",
      "19729    0.8\n",
      "19730    0.4\n",
      "19731    0.4\n",
      "19732    0.8\n",
      "19733    0.3\n",
      "19734    0.7\n",
      "19735    0.5\n",
      "19736    0.4\n",
      "19737    0.8\n",
      "19738    0.8\n",
      "19739    0.8\n",
      "19740    0.6\n",
      "19741    0.4\n",
      "19742    0.6\n",
      "19743    0.9\n",
      "19744    0.5\n",
      "19745    0.9\n",
      "19746    0.3\n",
      "19747    0.4\n",
      "19748    0.6\n",
      "19749    0.6\n",
      "Length: 19750, dtype: float64\n",
      "       model_lgbm  model_xgb  model_lr  model_gnb  model_rf\n",
      "0        0.851482   0.352662  0.705897   0.917059       0.9\n",
      "1        0.863427   0.785731  0.504901   0.625224       0.8\n",
      "2        0.576822   0.798868  0.843950   0.962931       0.9\n",
      "3        0.994141   0.986622  0.874679   0.999665       0.9\n",
      "4        0.874714   0.686413  0.826971   0.692121       0.4\n",
      "5        0.715654   0.336104  0.358530   0.977410       0.6\n",
      "6        0.544930   0.558781  0.196340   0.023366       0.8\n",
      "7        0.257953   0.212623  0.189119   0.948882       0.5\n",
      "8        0.987893   0.966610  0.727899   0.988889       0.7\n",
      "9        0.640657   0.734070  0.158370   0.124102       0.5\n",
      "10       0.966319   0.614487  0.724241   0.872082       0.5\n",
      "11       0.512569   0.428332  0.495848   0.154682       0.7\n",
      "12       0.254850   0.493507  0.494907   0.968297       0.7\n",
      "13       0.934423   0.788672  0.520099   0.783914       0.7\n",
      "14       0.415954   0.593235  0.227477   0.923330       0.7\n",
      "15       0.985765   0.939741  0.830090   0.850566       0.8\n",
      "16       0.557227   0.601931  0.631469   0.999968       0.6\n",
      "17       0.842163   0.571842  0.790139   0.013894       0.5\n",
      "18       0.466471   0.596406  0.711028   0.447891       0.6\n",
      "19       0.764775   0.163729  0.345350   0.991005       0.5\n",
      "20       0.212064   0.533242  0.410858   0.001864       0.6\n",
      "21       0.881634   0.694809  0.671003   0.999923       0.8\n",
      "22       0.701399   0.840170  0.526027   0.981774       0.9\n",
      "23       0.492596   0.332898  0.628189   0.182206       0.7\n",
      "24       0.396034   0.372093  0.319130   0.996874       0.7\n",
      "25       0.937271   0.939011  0.520741   0.997129       0.7\n",
      "26       0.291753   0.212753  0.021505   0.603489       0.7\n",
      "27       0.901517   0.851979  0.874636   0.998887       1.0\n",
      "28       0.987991   0.932168  0.718301   0.992001       0.8\n",
      "29       0.960306   0.942935  0.852119   0.989188       0.8\n",
      "...           ...        ...       ...        ...       ...\n",
      "19720    0.870668   0.694353  0.351473   0.349377       0.3\n",
      "19721    0.930004   0.978316  0.950206   0.194762       0.4\n",
      "19722    0.862305   0.735939  0.646834   0.999920       0.8\n",
      "19723    0.052884   0.143124  0.051144   0.060479       0.3\n",
      "19724    0.984390   0.972417  0.714908   0.829289       0.7\n",
      "19725    0.203997   0.425130  0.592237   0.194978       0.7\n",
      "19726    0.976387   0.773912  0.937944   0.712422       0.5\n",
      "19727    0.930989   0.645054  0.657052   0.999558       0.4\n",
      "19728    0.742029   0.830833  0.698263   0.814810       0.6\n",
      "19729    0.950512   0.638408  0.922234   0.999661       0.8\n",
      "19730    0.914559   0.384611  0.295532   0.064967       0.4\n",
      "19731    0.161911   0.439083  0.161059   0.989532       0.4\n",
      "19732    0.928817   0.954431  0.849946   0.998521       0.8\n",
      "19733    0.522341   0.672409  0.364925   0.126464       0.3\n",
      "19734    0.796814   0.776611  0.898277   0.995265       0.7\n",
      "19735    0.362361   0.547139  0.564060   0.546209       0.5\n",
      "19736    0.717455   0.606188  0.843222   0.985502       0.4\n",
      "19737    0.958586   0.712105  0.794930   0.999939       0.8\n",
      "19738    0.972767   0.929456  0.916064   0.999879       0.8\n",
      "19739    0.769036   0.533358  0.707413   0.998808       0.8\n",
      "19740    0.924853   0.941153  0.616709   0.534311       0.6\n",
      "19741    0.952210   0.910683  0.724355   0.996443       0.4\n",
      "19742    0.939629   0.388921  0.424083   0.603071       0.6\n",
      "19743    0.343974   0.534967  0.082458   0.982461       0.9\n",
      "19744    0.983541   0.927215  0.905288   0.996927       0.5\n",
      "19745    0.956976   0.923754  0.604571   0.059395       0.9\n",
      "19746    0.988301   0.976764  0.984851   0.998886       0.3\n",
      "19747    0.375416   0.536864  0.426250   0.503686       0.4\n",
      "19748    0.984367   0.979151  0.922155   0.938958       0.6\n",
      "19749    0.727442   0.428397  0.161529   0.234100       0.6\n",
      "\n",
      "[19750 rows x 5 columns]\n",
      "(19750, 2)\n"
     ]
    }
   ],
   "source": [
    "df_test_base_model_preds = predict_models(selected_test, base_models_preds_train)\n",
    "print(df_test_base_model_preds)\n",
    "df_test_base_model_preds_col_ordered = pd.DataFrame()\n",
    "for col in df_base_model_preds_train.columns:\n",
    "    df_test_base_model_preds_col_ordered[col] = df_test_base_model_preds[col]\n",
    "ensemble_preds_test = second_level_classifier_gbm.predict_proba(df_test_base_model_preds_col_ordered)\n",
    "print(ensemble_preds_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46861023, 0.5313898 ],\n",
       "       [0.3235243 , 0.6764757 ],\n",
       "       [0.00219959, 0.9978004 ],\n",
       "       ...,\n",
       "       [0.9429828 , 0.0570172 ],\n",
       "       [0.00711846, 0.99288154],\n",
       "       [0.9370421 , 0.06295786]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19750, 2)\n",
      "(19750, 2)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "print(ensemble_preds_test.shape)\n",
    "print(sub.shape)\n",
    "\n",
    "sub['target'] = ensemble_preds_test\n",
    "sub.to_csv(\"results/submit_results.csv\", index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/kaggle\", line 11, in <module>\n",
      "    load_entry_point('kaggle==1.5.3', 'console_scripts', 'kaggle')()\n",
      "  File \"/usr/lib/python3/dist-packages/pkg_resources/__init__.py\", line 480, in load_entry_point\n",
      "    return get_distribution(dist).load_entry_point(group, name)\n",
      "  File \"/usr/lib/python3/dist-packages/pkg_resources/__init__.py\", line 2693, in load_entry_point\n",
      "    return ep.load()\n",
      "  File \"/usr/lib/python3/dist-packages/pkg_resources/__init__.py\", line 2324, in load\n",
      "    return self.resolve()\n",
      "  File \"/usr/lib/python3/dist-packages/pkg_resources/__init__.py\", line 2330, in resolve\n",
      "    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
      "    api.authenticate()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 119, in authenticate\n",
      "    self._load_config(config_data)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 160, in _load_config\n",
      "    raise ValueError('Error: Missing %s in configuration.' % item)\n",
      "ValueError: Error: Missing username in configuration.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'kaggle competitions submit -c dont-overfit-ii -f results/submit_results.csv -m \"initial\"\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-11ca08c9a072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kaggle competitions submit -c dont-overfit-ii -f results/submit_results.csv -m \"initial\"\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2345\u001b[0m                 \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'kaggle competitions submit -c dont-overfit-ii -f results/submit_results.csv -m \"initial\"\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kaggle competitions submit -c dont-overfit-ii -f results/submit_results.csv -m \"initial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
